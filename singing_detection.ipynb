{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "file_path = 'singer_diarization_data.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming 'time_start' and 'end_time' are in milliseconds\n",
    "time_step = n_fft * 1000/22050  # Define your desired time step in milliseconds\n",
    "\n",
    "# Calculate the total time span\n",
    "total_time = df['end_time'].max()\n",
    "\n",
    "# Create an array with zeros initially\n",
    "label_array = np.zeros(int(total_time / time_step) + 1)\n",
    "\n",
    "# Iterate through rows and update the array based on the label\n",
    "for index, row in df.iterrows():\n",
    "    start_idx = int(row['start_time'] / time_step)\n",
    "    end_idx = int(row['end_time'] / time_step)\n",
    "\n",
    "    if row['label'] in ['singer1', 'singer2']:\n",
    "        label_array[start_idx:end_idx+1] = 1\n",
    "\n",
    "# Cast the array to integer type\n",
    "label_array = label_array.astype(int)\n",
    "\n",
    "print(label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the time_array\n",
    "result_df = pd.DataFrame({'time': np.arange(0, total_time + 1, time_step), 'value': label_array})\n",
    "\n",
    "# Write the DataFrame to a new CSV file\n",
    "result_df.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29534 ,  49208\n",
      "60.018696146967976 % Negative Values\n"
     ]
    }
   ],
   "source": [
    "#Ckeck the no. of -ve and +ve values to check class imbalance\n",
    "zero = 0\n",
    "one = 0\n",
    "\n",
    "for i in label_array:\n",
    "    if i==0:\n",
    "        zero+=1\n",
    "    elif i==1:\n",
    "        one+=1\n",
    "\n",
    "print(zero, \", \", one)\n",
    "\n",
    "#Find class imbalance\n",
    "print(zero/one*100, \"% Negative Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"singer_diarization.mp3\"\n",
    "#Load audio\n",
    "signal, sr = librosa.load(input)\n",
    "\n",
    "#Calculate MFCCs, delta MFCCs and delta delta MFCCs and concatenate them to get feature vector\n",
    "mfcc = librosa.feature.mfcc(y=signal, n_mfcc=13, n_fft=n_fft, sr=sr)\n",
    "del_mfcc = librosa.feature.delta(mfcc)\n",
    "del2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "mfcc_features = np.concatenate((mfcc, del_mfcc, del2_mfcc))\n",
    "\n",
    "mfcc_features = np.transpose(mfcc_features)\n",
    "\n",
    "#Genrate train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(mfcc_features, label_array, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\chinm\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(78, activation='relu', input_shape = (39,)),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(156, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(100, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(50, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(25, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(5, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# Create an instance of the F1Score metric.\n",
    "f1_score = F1Score(num_classes=2, average='micro')\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy', f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62993, 39)\n",
      "(62993,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 1: f1_score improved from -inf to 0.77033, saving model to ./ckpt1\\wght-imprv-01-1.00-0.77.hdf5\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0048 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 2/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9990 - f1_score: 0.7704\n",
      "Epoch 2: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0058 - accuracy: 0.9990 - f1_score: 0.7703\n",
      "Epoch 3/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9991 - f1_score: 0.7704\n",
      "Epoch 3: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 12s 6ms/step - loss: 0.0059 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 4/100\n",
      "1963/1969 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 4: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0050 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 5/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9991 - f1_score: 0.7704\n",
      "Epoch 5: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 6ms/step - loss: 0.0056 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 6/100\n",
      "1963/1969 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 6: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0050 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 7/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 7: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0031 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 8/100\n",
      "1967/1969 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9987 - f1_score: 0.7703\n",
      "Epoch 8: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0079 - accuracy: 0.9987 - f1_score: 0.7703\n",
      "Epoch 9/100\n",
      "1967/1969 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9993 - f1_score: 0.7704\n",
      "Epoch 9: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0045 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 10/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 10: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0051 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 11/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 11: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0058 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 12/100\n",
      "1963/1969 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9993 - f1_score: 0.7702\n",
      "Epoch 12: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0047 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 13/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9996 - f1_score: 0.7704\n",
      "Epoch 13: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0031 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 14/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 14: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0047 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 15/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 15: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0051 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 16/100\n",
      "1967/1969 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 16: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0033 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 17/100\n",
      "1967/1969 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 17: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0050 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 18/100\n",
      "1962/1969 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9993 - f1_score: 0.7705\n",
      "Epoch 18: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0047 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 19/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9990 - f1_score: 0.7703\n",
      "Epoch 19: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0071 - accuracy: 0.9990 - f1_score: 0.7703\n",
      "Epoch 20/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9991 - f1_score: 0.7704\n",
      "Epoch 20: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0049 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 21/100\n",
      "1967/1969 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9993 - f1_score: 0.7704\n",
      "Epoch 21: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0042 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 22/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 22: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0051 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 23/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 23: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0047 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 24/100\n",
      "1969/1969 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 24: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 15s 7ms/step - loss: 0.0058 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 25/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 25: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0044 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 26/100\n",
      "1962/1969 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9993 - f1_score: 0.7704\n",
      "Epoch 26: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0057 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 27/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9993 - f1_score: 0.7704\n",
      "Epoch 27: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 15s 8ms/step - loss: 0.0047 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 28/100\n",
      "1968/1969 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 28: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0054 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 29/100\n",
      "1967/1969 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 29: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 6ms/step - loss: 0.0056 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 30/100\n",
      "1969/1969 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 30: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0057 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 31/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 31: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0042 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 32/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 32: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0041 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 33/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 33: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0063 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 34/100\n",
      "1967/1969 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 34: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0055 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 35/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 35: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0043 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 36/100\n",
      "1968/1969 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 36: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0066 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 37/100\n",
      "1963/1969 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9993 - f1_score: 0.7705\n",
      "Epoch 37: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0047 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 38/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 38: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0065 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 39/100\n",
      "1969/1969 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 39: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0043 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 40/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 40: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0047 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 41/100\n",
      "1968/1969 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 41: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0038 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 42/100\n",
      "1968/1969 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9990 - f1_score: 0.7703\n",
      "Epoch 42: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0066 - accuracy: 0.9990 - f1_score: 0.7703\n",
      "Epoch 43/100\n",
      "1961/1969 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9993 - f1_score: 0.7704\n",
      "Epoch 43: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0057 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 44/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 44: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0075 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 45/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 45: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0035 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 46/100\n",
      "1962/1969 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9995 - f1_score: 0.7701\n",
      "Epoch 46: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0032 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 47/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 47: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0029 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 48/100\n",
      "1963/1969 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9996 - f1_score: 0.7704\n",
      "Epoch 48: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0037 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 49/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9994 - f1_score: 0.7704\n",
      "Epoch 49: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0040 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 50/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9989 - f1_score: 0.7703\n",
      "Epoch 50: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0096 - accuracy: 0.9989 - f1_score: 0.7703\n",
      "Epoch 51/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9993 - f1_score: 0.7705\n",
      "Epoch 51: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0051 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 52/100\n",
      "1967/1969 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 52: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 6ms/step - loss: 0.0056 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 53/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 53: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0049 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 54/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 54: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0028 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 55/100\n",
      "1969/1969 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 55: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 12s 6ms/step - loss: 0.0067 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 56/100\n",
      "1963/1969 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9994 - f1_score: 0.7704\n",
      "Epoch 56: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0043 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 57/100\n",
      "1967/1969 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 57: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0028 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 58/100\n",
      "1963/1969 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 58: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0039 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 59/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9995 - f1_score: 0.7704\n",
      "Epoch 59: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0047 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 60/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9993 - f1_score: 0.7702\n",
      "Epoch 60: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0047 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 61/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 61: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0057 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 62/100\n",
      "1968/1969 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 62: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0078 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 63/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 63: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0038 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 64/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9993 - f1_score: 0.7704\n",
      "Epoch 64: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 12s 6ms/step - loss: 0.0059 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 65/100\n",
      "1968/1969 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9994 - f1_score: 0.7704\n",
      "Epoch 65: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0043 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 66/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 66: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 6ms/step - loss: 0.0041 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 67/100\n",
      "1963/1969 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 67: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0037 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 68/100\n",
      "1961/1969 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9995 - f1_score: 0.7701\n",
      "Epoch 68: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0034 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 69/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9996 - f1_score: 0.7704\n",
      "Epoch 69: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 12s 6ms/step - loss: 0.0036 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 70/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 70: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 12s 6ms/step - loss: 0.0038 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 71/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 71: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0041 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 72/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9989 - f1_score: 0.7704\n",
      "Epoch 72: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0080 - accuracy: 0.9989 - f1_score: 0.7703\n",
      "Epoch 73/100\n",
      "1968/1969 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 73: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 12s 6ms/step - loss: 0.0062 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 74/100\n",
      "1963/1969 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9991 - f1_score: 0.7704\n",
      "Epoch 74: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 6ms/step - loss: 0.0062 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 75/100\n",
      "1967/1969 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9994 - f1_score: 0.7704\n",
      "Epoch 75: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0065 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 76/100\n",
      "1967/1969 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 76: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0062 - accuracy: 0.9991 - f1_score: 0.7703\n",
      "Epoch 77/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9993 - f1_score: 0.7705\n",
      "Epoch 77: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 12s 6ms/step - loss: 0.0055 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 78/100\n",
      "1968/1969 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 78: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 12s 6ms/step - loss: 0.0061 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 79/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9995 - f1_score: 0.7704\n",
      "Epoch 79: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 12s 6ms/step - loss: 0.0035 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 80/100\n",
      "1967/1969 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 80: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 6ms/step - loss: 0.0048 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 81/100\n",
      "1962/1969 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 81: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0032 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 82/100\n",
      "1967/1969 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 82: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0030 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 83/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 83: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0035 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 84/100\n",
      "1963/1969 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 84: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0115 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 85/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 85: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 12s 6ms/step - loss: 0.0040 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 86/100\n",
      "1962/1969 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9994 - f1_score: 0.7704\n",
      "Epoch 86: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 12s 6ms/step - loss: 0.0038 - accuracy: 0.9994 - f1_score: 0.7703\n",
      "Epoch 87/100\n",
      "1966/1969 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 87: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 12s 6ms/step - loss: 0.0037 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 88/100\n",
      "1968/1969 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9996 - f1_score: 0.7704\n",
      "Epoch 88: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0027 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 89/100\n",
      "1963/1969 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9993 - f1_score: 0.7704\n",
      "Epoch 89: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0057 - accuracy: 0.9993 - f1_score: 0.7703\n",
      "Epoch 90/100\n",
      "1969/1969 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 90: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0032 - accuracy: 0.9996 - f1_score: 0.7703\n",
      "Epoch 91/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9995 - f1_score: 0.7704\n",
      "Epoch 91: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0038 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 92/100\n",
      "1963/1969 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9989 - f1_score: 0.7702\n",
      "Epoch 92: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0146 - accuracy: 0.9989 - f1_score: 0.7703\n",
      "Epoch 93/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998 - f1_score: 0.7704\n",
      "Epoch 93: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0018 - accuracy: 0.9998 - f1_score: 0.7703\n",
      "Epoch 94/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9995 - f1_score: 0.7702\n",
      "Epoch 94: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0048 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 95/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9992 - f1_score: 0.7702\n",
      "Epoch 95: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 12s 6ms/step - loss: 0.0059 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 96/100\n",
      "1968/1969 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 96: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0052 - accuracy: 0.9992 - f1_score: 0.7703\n",
      "Epoch 97/100\n",
      "1968/1969 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 97: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0045 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 98/100\n",
      "1964/1969 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 98: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0036 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 99/100\n",
      "1965/1969 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 99: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 14s 7ms/step - loss: 0.0037 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 100/100\n",
      "1969/1969 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9995 - f1_score: 0.7703\n",
      "Epoch 100: f1_score did not improve from 0.77033\n",
      "1969/1969 [==============================] - 13s 7ms/step - loss: 0.0037 - accuracy: 0.9995 - f1_score: 0.7703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c26c05f010>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "filepath=\"./ckpt\" + str(i) + \"/wght-imprv-{epoch:02d}-{accuracy:.2f}-{f1_score:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='f1_score', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493/493 - 1s - loss: 0.0361 - accuracy: 0.9999 - f1_score: 0.7645 - 1s/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03609231859445572, 0.9998729825019836, 0.7645420432090759]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./ckpt1/100.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12593/12599 [============================>.] - ETA: 0s - loss: 0.1022 - accuracy: 0.9501 - f1_score: 0.8008\n",
      "Epoch 1: accuracy improved from -inf to 0.95007, saving model to ./batch_size-5\\wght-imprv-01-0.95-0.80.hdf5\n",
      "12599/12599 [==============================] - 85s 7ms/step - loss: 0.1022 - accuracy: 0.9501 - f1_score: 0.8008\n",
      "Epoch 2/50\n",
      "12597/12599 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9913 - f1_score: 0.8977\n",
      "Epoch 2: accuracy improved from 0.95007 to 0.99128, saving model to ./batch_size-5\\wght-imprv-02-0.99-0.90.hdf5\n",
      "12599/12599 [==============================] - 85s 7ms/step - loss: 0.0333 - accuracy: 0.9913 - f1_score: 0.8977\n",
      "Epoch 3/50\n",
      "12594/12599 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9932 - f1_score: 0.9058\n",
      "Epoch 3: accuracy improved from 0.99128 to 0.99322, saving model to ./batch_size-5\\wght-imprv-03-0.99-0.91.hdf5\n",
      "12599/12599 [==============================] - 82s 6ms/step - loss: 0.0259 - accuracy: 0.9932 - f1_score: 0.9058\n",
      "Epoch 4/50\n",
      "12592/12599 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9946 - f1_score: 0.9390\n",
      "Epoch 4: accuracy improved from 0.99322 to 0.99462, saving model to ./batch_size-5\\wght-imprv-04-0.99-0.94.hdf5\n",
      "12599/12599 [==============================] - 84s 7ms/step - loss: 0.0227 - accuracy: 0.9946 - f1_score: 0.9390\n",
      "Epoch 5/50\n",
      "12599/12599 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9935 - f1_score: 0.9619\n",
      "Epoch 5: accuracy did not improve from 0.99462\n",
      "12599/12599 [==============================] - 87s 7ms/step - loss: 0.0255 - accuracy: 0.9935 - f1_score: 0.9619\n",
      "Epoch 6/50\n",
      "12599/12599 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9946 - f1_score: 0.9379\n",
      "Epoch 6: accuracy improved from 0.99462 to 0.99463, saving model to ./batch_size-5\\wght-imprv-06-0.99-0.94.hdf5\n",
      "12599/12599 [==============================] - 83s 7ms/step - loss: 0.0225 - accuracy: 0.9946 - f1_score: 0.9379\n",
      "Epoch 7/50\n",
      "12596/12599 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9946 - f1_score: 0.9574\n",
      "Epoch 7: accuracy did not improve from 0.99463\n",
      "12599/12599 [==============================] - 83s 7ms/step - loss: 0.0267 - accuracy: 0.9946 - f1_score: 0.9574\n",
      "Epoch 8/50\n",
      "12595/12599 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9946 - f1_score: 0.9615\n",
      "Epoch 8: accuracy did not improve from 0.99463\n",
      "12599/12599 [==============================] - 81s 6ms/step - loss: 0.0238 - accuracy: 0.9946 - f1_score: 0.9615\n",
      "Epoch 9/50\n",
      "12591/12599 [============================>.] - ETA: 0s - loss: 0.0337 - accuracy: 0.9939 - f1_score: 0.9663\n",
      "Epoch 9: accuracy did not improve from 0.99463\n",
      "12599/12599 [==============================] - 78s 6ms/step - loss: 0.0336 - accuracy: 0.9939 - f1_score: 0.9663\n",
      "Epoch 10/50\n",
      "12597/12599 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.9947 - f1_score: 0.9764\n",
      "Epoch 10: accuracy improved from 0.99463 to 0.99468, saving model to ./batch_size-5\\wght-imprv-10-0.99-0.98.hdf5\n",
      "12599/12599 [==============================] - 77s 6ms/step - loss: 0.0316 - accuracy: 0.9947 - f1_score: 0.9764\n",
      "Epoch 11/50\n",
      "12599/12599 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9942 - f1_score: 0.9808\n",
      "Epoch 11: accuracy did not improve from 0.99468\n",
      "12599/12599 [==============================] - 77s 6ms/step - loss: 0.0329 - accuracy: 0.9942 - f1_score: 0.9808\n",
      "Epoch 12/50\n",
      "12595/12599 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9938 - f1_score: 0.9669\n",
      "Epoch 12: accuracy did not improve from 0.99468\n",
      "12599/12599 [==============================] - 77s 6ms/step - loss: 0.0355 - accuracy: 0.9938 - f1_score: 0.9669\n",
      "Epoch 13/50\n",
      "12591/12599 [============================>.] - ETA: 0s - loss: 0.0304 - accuracy: 0.9948 - f1_score: 0.9814\n",
      "Epoch 13: accuracy improved from 0.99468 to 0.99481, saving model to ./batch_size-5\\wght-imprv-13-0.99-0.98.hdf5\n",
      "12599/12599 [==============================] - 78s 6ms/step - loss: 0.0304 - accuracy: 0.9948 - f1_score: 0.9814\n",
      "Epoch 14/50\n",
      "12592/12599 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.9937 - f1_score: 0.9803\n",
      "Epoch 14: accuracy did not improve from 0.99481\n",
      "12599/12599 [==============================] - 77s 6ms/step - loss: 0.0348 - accuracy: 0.9937 - f1_score: 0.9803\n",
      "Epoch 15/50\n",
      "12596/12599 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9947 - f1_score: 0.9875\n",
      "Epoch 15: accuracy did not improve from 0.99481\n",
      "12599/12599 [==============================] - 79s 6ms/step - loss: 0.0266 - accuracy: 0.9947 - f1_score: 0.9875\n",
      "Epoch 16/50\n",
      "12599/12599 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9953 - f1_score: 0.9873\n",
      "Epoch 16: accuracy improved from 0.99481 to 0.99532, saving model to ./batch_size-5\\wght-imprv-16-1.00-0.99.hdf5\n",
      "12599/12599 [==============================] - 87s 7ms/step - loss: 0.0324 - accuracy: 0.9953 - f1_score: 0.9873\n",
      "Epoch 17/50\n",
      "12599/12599 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9929 - f1_score: 0.9795\n",
      "Epoch 17: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 87s 7ms/step - loss: 0.0432 - accuracy: 0.9929 - f1_score: 0.9795\n",
      "Epoch 18/50\n",
      "12592/12599 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9842 - f1_score: 0.9762\n",
      "Epoch 18: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 89s 7ms/step - loss: 0.0796 - accuracy: 0.9842 - f1_score: 0.9762\n",
      "Epoch 19/50\n",
      "12591/12599 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9839 - f1_score: 0.9750\n",
      "Epoch 19: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 88s 7ms/step - loss: 0.0686 - accuracy: 0.9839 - f1_score: 0.9750\n",
      "Epoch 20/50\n",
      "12598/12599 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9832 - f1_score: 0.9713\n",
      "Epoch 20: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 83s 7ms/step - loss: 0.0579 - accuracy: 0.9832 - f1_score: 0.9713\n",
      "Epoch 21/50\n",
      "12597/12599 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 0.9833 - f1_score: 0.9781\n",
      "Epoch 21: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 83s 7ms/step - loss: 0.0646 - accuracy: 0.9833 - f1_score: 0.9781\n",
      "Epoch 22/50\n",
      "12594/12599 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9820 - f1_score: 0.9771\n",
      "Epoch 22: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 80s 6ms/step - loss: 0.0871 - accuracy: 0.9820 - f1_score: 0.9771\n",
      "Epoch 23/50\n",
      "12597/12599 [============================>.] - ETA: 0s - loss: 0.0857 - accuracy: 0.9830 - f1_score: 0.9781\n",
      "Epoch 23: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 77s 6ms/step - loss: 0.0857 - accuracy: 0.9830 - f1_score: 0.9781\n",
      "Epoch 24/50\n",
      "12592/12599 [============================>.] - ETA: 0s - loss: 0.0811 - accuracy: 0.9834 - f1_score: 0.9801\n",
      "Epoch 24: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 88s 7ms/step - loss: 0.0811 - accuracy: 0.9834 - f1_score: 0.9801\n",
      "Epoch 25/50\n",
      "12598/12599 [============================>.] - ETA: 0s - loss: 0.0893 - accuracy: 0.9831 - f1_score: 0.9792\n",
      "Epoch 25: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 82s 7ms/step - loss: 0.0893 - accuracy: 0.9831 - f1_score: 0.9792\n",
      "Epoch 26/50\n",
      "12594/12599 [============================>.] - ETA: 0s - loss: 0.0898 - accuracy: 0.9839 - f1_score: 0.9780\n",
      "Epoch 26: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 78s 6ms/step - loss: 0.0898 - accuracy: 0.9839 - f1_score: 0.9780\n",
      "Epoch 27/50\n",
      "12594/12599 [============================>.] - ETA: 0s - loss: 0.0827 - accuracy: 0.9835 - f1_score: 0.9826\n",
      "Epoch 27: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 77s 6ms/step - loss: 0.0828 - accuracy: 0.9834 - f1_score: 0.9826\n",
      "Epoch 28/50\n",
      "12599/12599 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9825 - f1_score: 0.9760\n",
      "Epoch 28: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 78s 6ms/step - loss: 0.0931 - accuracy: 0.9825 - f1_score: 0.9760\n",
      "Epoch 29/50\n",
      "12594/12599 [============================>.] - ETA: 0s - loss: 0.2048 - accuracy: 0.9402 - f1_score: 0.9430\n",
      "Epoch 29: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 85s 7ms/step - loss: 0.2049 - accuracy: 0.9402 - f1_score: 0.9430\n",
      "Epoch 30/50\n",
      "12592/12599 [============================>.] - ETA: 0s - loss: 0.2439 - accuracy: 0.9241 - f1_score: 0.9318\n",
      "Epoch 30: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 83s 7ms/step - loss: 0.2439 - accuracy: 0.9241 - f1_score: 0.9318\n",
      "Epoch 31/50\n",
      "12596/12599 [============================>.] - ETA: 0s - loss: 0.2460 - accuracy: 0.9238 - f1_score: 0.9302\n",
      "Epoch 31: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 77s 6ms/step - loss: 0.2459 - accuracy: 0.9238 - f1_score: 0.9302\n",
      "Epoch 32/50\n",
      "12595/12599 [============================>.] - ETA: 0s - loss: 0.2427 - accuracy: 0.9241 - f1_score: 0.9343\n",
      "Epoch 32: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 82s 6ms/step - loss: 0.2426 - accuracy: 0.9241 - f1_score: 0.9343\n",
      "Epoch 33/50\n",
      "12596/12599 [============================>.] - ETA: 0s - loss: 0.2429 - accuracy: 0.9245 - f1_score: 0.9358\n",
      "Epoch 33: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 88s 7ms/step - loss: 0.2429 - accuracy: 0.9245 - f1_score: 0.9358\n",
      "Epoch 34/50\n",
      "12599/12599 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.9244 - f1_score: 0.9364\n",
      "Epoch 34: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 85s 7ms/step - loss: 0.2390 - accuracy: 0.9244 - f1_score: 0.9364\n",
      "Epoch 35/50\n",
      "12593/12599 [============================>.] - ETA: 0s - loss: 0.2517 - accuracy: 0.9220 - f1_score: 0.9344\n",
      "Epoch 35: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 83s 7ms/step - loss: 0.2516 - accuracy: 0.9221 - f1_score: 0.9344\n",
      "Epoch 36/50\n",
      "12593/12599 [============================>.] - ETA: 0s - loss: 0.2333 - accuracy: 0.9206 - f1_score: 0.9278\n",
      "Epoch 36: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 81s 6ms/step - loss: 0.2333 - accuracy: 0.9206 - f1_score: 0.9277\n",
      "Epoch 37/50\n",
      "12598/12599 [============================>.] - ETA: 0s - loss: 0.1397 - accuracy: 0.9237 - f1_score: 0.9201\n",
      "Epoch 37: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 81s 6ms/step - loss: 0.1397 - accuracy: 0.9237 - f1_score: 0.9201\n",
      "Epoch 38/50\n",
      "12598/12599 [============================>.] - ETA: 0s - loss: 0.1385 - accuracy: 0.9257 - f1_score: 0.9328\n",
      "Epoch 38: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 85s 7ms/step - loss: 0.1385 - accuracy: 0.9257 - f1_score: 0.9328\n",
      "Epoch 39/50\n",
      "12593/12599 [============================>.] - ETA: 0s - loss: 0.1433 - accuracy: 0.9223 - f1_score: 0.9319\n",
      "Epoch 39: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 87s 7ms/step - loss: 0.1433 - accuracy: 0.9223 - f1_score: 0.9319\n",
      "Epoch 40/50\n",
      "12597/12599 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9231 - f1_score: 0.9273\n",
      "Epoch 40: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 87s 7ms/step - loss: 0.1339 - accuracy: 0.9231 - f1_score: 0.9273\n",
      "Epoch 41/50\n",
      "12599/12599 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9636 - f1_score: 0.9358\n",
      "Epoch 41: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 82s 7ms/step - loss: 0.0766 - accuracy: 0.9636 - f1_score: 0.9358\n",
      "Epoch 42/50\n",
      "12596/12599 [============================>.] - ETA: 0s - loss: 0.1374 - accuracy: 0.9211 - f1_score: 0.9384\n",
      "Epoch 42: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 86s 7ms/step - loss: 0.1375 - accuracy: 0.9211 - f1_score: 0.9384\n",
      "Epoch 43/50\n",
      "12594/12599 [============================>.] - ETA: 0s - loss: 0.1013 - accuracy: 0.9464 - f1_score: 0.9263\n",
      "Epoch 43: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 80s 6ms/step - loss: 0.1013 - accuracy: 0.9464 - f1_score: 0.9262\n",
      "Epoch 44/50\n",
      "12591/12599 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.9668 - f1_score: 0.9246\n",
      "Epoch 44: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 79s 6ms/step - loss: 0.0739 - accuracy: 0.9668 - f1_score: 0.9246\n",
      "Epoch 45/50\n",
      "12595/12599 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9712 - f1_score: 0.9205\n",
      "Epoch 45: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 77s 6ms/step - loss: 0.0661 - accuracy: 0.9712 - f1_score: 0.9205\n",
      "Epoch 46/50\n",
      "12594/12599 [============================>.] - ETA: 0s - loss: 0.0637 - accuracy: 0.9725 - f1_score: 0.9355\n",
      "Epoch 46: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 77s 6ms/step - loss: 0.0637 - accuracy: 0.9725 - f1_score: 0.9355\n",
      "Epoch 47/50\n",
      "12595/12599 [============================>.] - ETA: 0s - loss: 0.1431 - accuracy: 0.9126 - f1_score: 0.9200\n",
      "Epoch 47: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 78s 6ms/step - loss: 0.1431 - accuracy: 0.9126 - f1_score: 0.9200\n",
      "Epoch 48/50\n",
      "12596/12599 [============================>.] - ETA: 0s - loss: 0.1432 - accuracy: 0.9237 - f1_score: 0.9232\n",
      "Epoch 48: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 77s 6ms/step - loss: 0.1432 - accuracy: 0.9237 - f1_score: 0.9232\n",
      "Epoch 49/50\n",
      "12595/12599 [============================>.] - ETA: 0s - loss: 0.1399 - accuracy: 0.9225 - f1_score: 0.9314\n",
      "Epoch 49: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 77s 6ms/step - loss: 0.1399 - accuracy: 0.9225 - f1_score: 0.9315\n",
      "Epoch 50/50\n",
      "12598/12599 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9245 - f1_score: 0.9380\n",
      "Epoch 50: accuracy did not improve from 0.99532\n",
      "12599/12599 [==============================] - 77s 6ms/step - loss: 0.1518 - accuracy: 0.9245 - f1_score: 0.9380\n",
      "Epoch 1/50\n",
      "2519/2520 [============================>.] - ETA: 0s - loss: 0.1611 - accuracy: 0.9508 - f1_score: 0.7904\n",
      "Epoch 1: accuracy improved from -inf to 0.95082, saving model to ./batch_size-25\\wght-imprv-01-0.95-0.79.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.1610 - accuracy: 0.9508 - f1_score: 0.7905\n",
      "Epoch 2/50\n",
      "2519/2520 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9955 - f1_score: 0.8723\n",
      "Epoch 2: accuracy improved from 0.95082 to 0.99546, saving model to ./batch_size-25\\wght-imprv-02-1.00-0.87.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0329 - accuracy: 0.9955 - f1_score: 0.8723\n",
      "Epoch 3/50\n",
      "2514/2520 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9962 - f1_score: 0.8920\n",
      "Epoch 3: accuracy improved from 0.99546 to 0.99621, saving model to ./batch_size-25\\wght-imprv-03-1.00-0.89.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0243 - accuracy: 0.9962 - f1_score: 0.8920\n",
      "Epoch 4/50\n",
      "2517/2520 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9969 - f1_score: 0.9419\n",
      "Epoch 4: accuracy improved from 0.99621 to 0.99689, saving model to ./batch_size-25\\wght-imprv-04-1.00-0.94.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0163 - accuracy: 0.9969 - f1_score: 0.9419\n",
      "Epoch 5/50\n",
      "2514/2520 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9969 - f1_score: 0.9565\n",
      "Epoch 5: accuracy did not improve from 0.99689\n",
      "2520/2520 [==============================] - 15s 6ms/step - loss: 0.0154 - accuracy: 0.9969 - f1_score: 0.9564\n",
      "Epoch 6/50\n",
      "2513/2520 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9973 - f1_score: 0.9637\n",
      "Epoch 6: accuracy improved from 0.99689 to 0.99733, saving model to ./batch_size-25\\wght-imprv-06-1.00-0.96.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0122 - accuracy: 0.9973 - f1_score: 0.9636\n",
      "Epoch 7/50\n",
      "2514/2520 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9974 - f1_score: 0.9431\n",
      "Epoch 7: accuracy improved from 0.99733 to 0.99741, saving model to ./batch_size-25\\wght-imprv-07-1.00-0.94.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0135 - accuracy: 0.9974 - f1_score: 0.9431\n",
      "Epoch 8/50\n",
      "2514/2520 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9978 - f1_score: 0.9521\n",
      "Epoch 8: accuracy improved from 0.99741 to 0.99778, saving model to ./batch_size-25\\wght-imprv-08-1.00-0.95.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0108 - accuracy: 0.9978 - f1_score: 0.9521\n",
      "Epoch 9/50\n",
      "2519/2520 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9980 - f1_score: 0.9631\n",
      "Epoch 9: accuracy improved from 0.99778 to 0.99798, saving model to ./batch_size-25\\wght-imprv-09-1.00-0.96.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0112 - accuracy: 0.9980 - f1_score: 0.9631\n",
      "Epoch 10/50\n",
      "2518/2520 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9975 - f1_score: 0.9687\n",
      "Epoch 10: accuracy did not improve from 0.99798\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0136 - accuracy: 0.9975 - f1_score: 0.9687\n",
      "Epoch 11/50\n",
      "2514/2520 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9975 - f1_score: 0.9585\n",
      "Epoch 11: accuracy did not improve from 0.99798\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0110 - accuracy: 0.9975 - f1_score: 0.9585\n",
      "Epoch 12/50\n",
      "2515/2520 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9982 - f1_score: 0.9695\n",
      "Epoch 12: accuracy improved from 0.99798 to 0.99819, saving model to ./batch_size-25\\wght-imprv-12-1.00-0.97.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0083 - accuracy: 0.9982 - f1_score: 0.9695\n",
      "Epoch 13/50\n",
      "2518/2520 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9984 - f1_score: 0.9750\n",
      "Epoch 13: accuracy improved from 0.99819 to 0.99838, saving model to ./batch_size-25\\wght-imprv-13-1.00-0.97.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0079 - accuracy: 0.9984 - f1_score: 0.9750\n",
      "Epoch 14/50\n",
      "2519/2520 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.9980 - f1_score: 0.9753\n",
      "Epoch 14: accuracy did not improve from 0.99838\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0090 - accuracy: 0.9980 - f1_score: 0.9753\n",
      "Epoch 15/50\n",
      "2517/2520 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9976 - f1_score: 0.9833\n",
      "Epoch 15: accuracy did not improve from 0.99838\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0114 - accuracy: 0.9976 - f1_score: 0.9833\n",
      "Epoch 16/50\n",
      "2515/2520 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9985 - f1_score: 0.9831\n",
      "Epoch 16: accuracy improved from 0.99838 to 0.99846, saving model to ./batch_size-25\\wght-imprv-16-1.00-0.98.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0074 - accuracy: 0.9985 - f1_score: 0.9831\n",
      "Epoch 17/50\n",
      "2520/2520 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9981 - f1_score: 0.9851\n",
      "Epoch 17: accuracy did not improve from 0.99846\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0096 - accuracy: 0.9981 - f1_score: 0.9851\n",
      "Epoch 18/50\n",
      "2514/2520 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9975 - f1_score: 0.9819\n",
      "Epoch 18: accuracy did not improve from 0.99846\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0141 - accuracy: 0.9975 - f1_score: 0.9819\n",
      "Epoch 19/50\n",
      "2515/2520 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9980 - f1_score: 0.9868\n",
      "Epoch 19: accuracy did not improve from 0.99846\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0085 - accuracy: 0.9980 - f1_score: 0.9868\n",
      "Epoch 20/50\n",
      "2516/2520 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9983 - f1_score: 0.9888\n",
      "Epoch 20: accuracy did not improve from 0.99846\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0076 - accuracy: 0.9983 - f1_score: 0.9888\n",
      "Epoch 21/50\n",
      "2513/2520 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9985 - f1_score: 0.9864\n",
      "Epoch 21: accuracy improved from 0.99846 to 0.99852, saving model to ./batch_size-25\\wght-imprv-21-1.00-0.99.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0078 - accuracy: 0.9985 - f1_score: 0.9864\n",
      "Epoch 22/50\n",
      "2517/2520 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9977 - f1_score: 0.9871\n",
      "Epoch 22: accuracy did not improve from 0.99852\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0089 - accuracy: 0.9977 - f1_score: 0.9871\n",
      "Epoch 23/50\n",
      "2519/2520 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9979 - f1_score: 0.9843\n",
      "Epoch 23: accuracy did not improve from 0.99852\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0110 - accuracy: 0.9979 - f1_score: 0.9842\n",
      "Epoch 24/50\n",
      "2516/2520 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9980 - f1_score: 0.9822\n",
      "Epoch 24: accuracy did not improve from 0.99852\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0087 - accuracy: 0.9980 - f1_score: 0.9822\n",
      "Epoch 25/50\n",
      "2516/2520 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9972 - f1_score: 0.9863\n",
      "Epoch 25: accuracy did not improve from 0.99852\n",
      "2520/2520 [==============================] - 15s 6ms/step - loss: 0.0134 - accuracy: 0.9972 - f1_score: 0.9864\n",
      "Epoch 26/50\n",
      "2517/2520 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9983 - f1_score: 0.9894\n",
      "Epoch 26: accuracy did not improve from 0.99852\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0083 - accuracy: 0.9983 - f1_score: 0.9894\n",
      "Epoch 27/50\n",
      "2514/2520 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9988 - f1_score: 0.9916\n",
      "Epoch 27: accuracy improved from 0.99852 to 0.99884, saving model to ./batch_size-25\\wght-imprv-27-1.00-0.99.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0066 - accuracy: 0.9988 - f1_score: 0.9917\n",
      "Epoch 28/50\n",
      "2514/2520 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9977 - f1_score: 0.9867\n",
      "Epoch 28: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0116 - accuracy: 0.9977 - f1_score: 0.9867\n",
      "Epoch 29/50\n",
      "2513/2520 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9987 - f1_score: 0.9929\n",
      "Epoch 29: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0057 - accuracy: 0.9987 - f1_score: 0.9930\n",
      "Epoch 30/50\n",
      "2516/2520 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9975 - f1_score: 0.9853\n",
      "Epoch 30: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0114 - accuracy: 0.9975 - f1_score: 0.9853\n",
      "Epoch 31/50\n",
      "2517/2520 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9982 - f1_score: 0.9926\n",
      "Epoch 31: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 18s 7ms/step - loss: 0.0085 - accuracy: 0.9982 - f1_score: 0.9926\n",
      "Epoch 32/50\n",
      "2518/2520 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9980 - f1_score: 0.9927\n",
      "Epoch 32: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0078 - accuracy: 0.9980 - f1_score: 0.9928\n",
      "Epoch 33/50\n",
      "2515/2520 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9984 - f1_score: 0.9955\n",
      "Epoch 33: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0063 - accuracy: 0.9984 - f1_score: 0.9955\n",
      "Epoch 34/50\n",
      "2516/2520 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9980 - f1_score: 0.9939\n",
      "Epoch 34: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 18s 7ms/step - loss: 0.0109 - accuracy: 0.9980 - f1_score: 0.9939\n",
      "Epoch 35/50\n",
      "2514/2520 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9982 - f1_score: 0.9955\n",
      "Epoch 35: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 17s 7ms/step - loss: 0.0077 - accuracy: 0.9982 - f1_score: 0.9954\n",
      "Epoch 36/50\n",
      "2517/2520 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9975 - f1_score: 0.9872\n",
      "Epoch 36: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0142 - accuracy: 0.9975 - f1_score: 0.9872\n",
      "Epoch 37/50\n",
      "2515/2520 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9985 - f1_score: 0.9924\n",
      "Epoch 37: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0064 - accuracy: 0.9985 - f1_score: 0.9924\n",
      "Epoch 38/50\n",
      "2517/2520 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9979 - f1_score: 0.9936\n",
      "Epoch 38: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0176 - accuracy: 0.9979 - f1_score: 0.9937\n",
      "Epoch 39/50\n",
      "2517/2520 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9979 - f1_score: 0.9915\n",
      "Epoch 39: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0083 - accuracy: 0.9979 - f1_score: 0.9915\n",
      "Epoch 40/50\n",
      "2515/2520 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9982 - f1_score: 0.9919\n",
      "Epoch 40: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0085 - accuracy: 0.9982 - f1_score: 0.9919\n",
      "Epoch 41/50\n",
      "2512/2520 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9983 - f1_score: 0.9827\n",
      "Epoch 41: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 18s 7ms/step - loss: 0.0123 - accuracy: 0.9983 - f1_score: 0.9828\n",
      "Epoch 42/50\n",
      "2520/2520 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9984 - f1_score: 0.9886\n",
      "Epoch 42: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0078 - accuracy: 0.9984 - f1_score: 0.9886\n",
      "Epoch 43/50\n",
      "2513/2520 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9983 - f1_score: 0.9908\n",
      "Epoch 43: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 18s 7ms/step - loss: 0.0078 - accuracy: 0.9983 - f1_score: 0.9908\n",
      "Epoch 44/50\n",
      "2517/2520 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9987 - f1_score: 0.9954\n",
      "Epoch 44: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 18s 7ms/step - loss: 0.0075 - accuracy: 0.9987 - f1_score: 0.9954\n",
      "Epoch 45/50\n",
      "2520/2520 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9980 - f1_score: 0.9951\n",
      "Epoch 45: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 17s 7ms/step - loss: 0.0109 - accuracy: 0.9980 - f1_score: 0.9951\n",
      "Epoch 46/50\n",
      "2513/2520 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9980 - f1_score: 0.9911\n",
      "Epoch 46: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0099 - accuracy: 0.9980 - f1_score: 0.9911\n",
      "Epoch 47/50\n",
      "2513/2520 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9988 - f1_score: 0.9953\n",
      "Epoch 47: accuracy did not improve from 0.99884\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0058 - accuracy: 0.9988 - f1_score: 0.9953\n",
      "Epoch 48/50\n",
      "2519/2520 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9989 - f1_score: 0.9979\n",
      "Epoch 48: accuracy improved from 0.99884 to 0.99894, saving model to ./batch_size-25\\wght-imprv-48-1.00-1.00.hdf5\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0054 - accuracy: 0.9989 - f1_score: 0.9979\n",
      "Epoch 49/50\n",
      "2515/2520 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9980 - f1_score: 0.9950\n",
      "Epoch 49: accuracy did not improve from 0.99894\n",
      "2520/2520 [==============================] - 17s 7ms/step - loss: 0.0140 - accuracy: 0.9980 - f1_score: 0.9950\n",
      "Epoch 50/50\n",
      "2515/2520 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9986 - f1_score: 0.9973\n",
      "Epoch 50: accuracy did not improve from 0.99894\n",
      "2520/2520 [==============================] - 16s 6ms/step - loss: 0.0059 - accuracy: 0.9986 - f1_score: 0.9973\n",
      "Epoch 1/50\n",
      "499/504 [============================>.] - ETA: 0s - loss: 0.1997 - accuracy: 0.9157 - f1_score: 0.7724\n",
      "Epoch 1: accuracy improved from -inf to 0.91636, saving model to ./batch_size-125\\wght-imprv-01-0.92-0.77.hdf5\n",
      "504/504 [==============================] - 4s 6ms/step - loss: 0.1981 - accuracy: 0.9164 - f1_score: 0.7726\n",
      "Epoch 2/50\n",
      "499/504 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.9879 - f1_score: 0.7984\n",
      "Epoch 2: accuracy improved from 0.91636 to 0.98792, saving model to ./batch_size-125\\wght-imprv-02-0.99-0.80.hdf5\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 0.0385 - accuracy: 0.9879 - f1_score: 0.7984\n",
      "Epoch 3/50\n",
      "499/504 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9902 - f1_score: 0.8186\n",
      "Epoch 3: accuracy improved from 0.98792 to 0.99022, saving model to ./batch_size-125\\wght-imprv-03-0.99-0.82.hdf5\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0303 - accuracy: 0.9902 - f1_score: 0.8187\n",
      "Epoch 4/50\n",
      "498/504 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9904 - f1_score: 0.8244\n",
      "Epoch 4: accuracy improved from 0.99022 to 0.99033, saving model to ./batch_size-125\\wght-imprv-04-0.99-0.83.hdf5\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.9903 - f1_score: 0.8250\n",
      "Epoch 5/50\n",
      "496/504 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9906 - f1_score: 0.8614\n",
      "Epoch 5: accuracy improved from 0.99033 to 0.99055, saving model to ./batch_size-125\\wght-imprv-05-0.99-0.86.hdf5\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0245 - accuracy: 0.9906 - f1_score: 0.8610\n",
      "Epoch 6/50\n",
      "501/504 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9908 - f1_score: 0.8689\n",
      "Epoch 6: accuracy improved from 0.99055 to 0.99086, saving model to ./batch_size-125\\wght-imprv-06-0.99-0.87.hdf5\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 0.0225 - accuracy: 0.9909 - f1_score: 0.8691\n",
      "Epoch 7/50\n",
      "499/504 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.9908 - f1_score: 0.8737\n",
      "Epoch 7: accuracy did not improve from 0.99086\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0233 - accuracy: 0.9908 - f1_score: 0.8734\n",
      "Epoch 8/50\n",
      "500/504 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9922 - f1_score: 0.8867\n",
      "Epoch 8: accuracy improved from 0.99086 to 0.99214, saving model to ./batch_size-125\\wght-imprv-08-0.99-0.89.hdf5\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0198 - accuracy: 0.9921 - f1_score: 0.8867\n",
      "Epoch 9/50\n",
      "500/504 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9925 - f1_score: 0.8955\n",
      "Epoch 9: accuracy improved from 0.99214 to 0.99255, saving model to ./batch_size-125\\wght-imprv-09-0.99-0.90.hdf5\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0208 - accuracy: 0.9926 - f1_score: 0.8957\n",
      "Epoch 10/50\n",
      "499/504 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9929 - f1_score: 0.9038\n",
      "Epoch 10: accuracy improved from 0.99255 to 0.99298, saving model to ./batch_size-125\\wght-imprv-10-0.99-0.90.hdf5\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 0.0198 - accuracy: 0.9930 - f1_score: 0.9032\n",
      "Epoch 11/50\n",
      "501/504 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9950 - f1_score: 0.9221\n",
      "Epoch 11: accuracy improved from 0.99298 to 0.99503, saving model to ./batch_size-125\\wght-imprv-11-1.00-0.92.hdf5\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0163 - accuracy: 0.9950 - f1_score: 0.9221\n",
      "Epoch 12/50\n",
      "497/504 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9962 - f1_score: 0.9359\n",
      "Epoch 12: accuracy improved from 0.99503 to 0.99611, saving model to ./batch_size-125\\wght-imprv-12-1.00-0.94.hdf5\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0145 - accuracy: 0.9961 - f1_score: 0.9360\n",
      "Epoch 13/50\n",
      "504/504 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9963 - f1_score: 0.9340\n",
      "Epoch 13: accuracy improved from 0.99611 to 0.99630, saving model to ./batch_size-125\\wght-imprv-13-1.00-0.93.hdf5\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0127 - accuracy: 0.9963 - f1_score: 0.9340\n",
      "Epoch 14/50\n",
      "496/504 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9968 - f1_score: 0.9648\n",
      "Epoch 14: accuracy improved from 0.99630 to 0.99679, saving model to ./batch_size-125\\wght-imprv-14-1.00-0.96.hdf5\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0115 - accuracy: 0.9968 - f1_score: 0.9646\n",
      "Epoch 15/50\n",
      "501/504 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9965 - f1_score: 0.9536\n",
      "Epoch 15: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0124 - accuracy: 0.9964 - f1_score: 0.9536\n",
      "Epoch 16/50\n",
      "504/504 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9960 - f1_score: 0.9541\n",
      "Epoch 16: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 0.0124 - accuracy: 0.9960 - f1_score: 0.9541\n",
      "Epoch 17/50\n",
      "497/504 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9965 - f1_score: 0.9490\n",
      "Epoch 17: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0123 - accuracy: 0.9964 - f1_score: 0.9492\n",
      "Epoch 18/50\n",
      "499/504 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9960 - f1_score: 0.9532\n",
      "Epoch 18: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0132 - accuracy: 0.9960 - f1_score: 0.9535\n",
      "Epoch 19/50\n",
      "498/504 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9964 - f1_score: 0.9676\n",
      "Epoch 19: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 0.0116 - accuracy: 0.9965 - f1_score: 0.9677\n",
      "Epoch 20/50\n",
      "500/504 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9959 - f1_score: 0.9738\n",
      "Epoch 20: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0125 - accuracy: 0.9958 - f1_score: 0.9734\n",
      "Epoch 21/50\n",
      "504/504 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9964 - f1_score: 0.9555\n",
      "Epoch 21: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0114 - accuracy: 0.9964 - f1_score: 0.9555\n",
      "Epoch 22/50\n",
      "504/504 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9962 - f1_score: 0.9539\n",
      "Epoch 22: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0125 - accuracy: 0.9962 - f1_score: 0.9539\n",
      "Epoch 23/50\n",
      "501/504 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9963 - f1_score: 0.9675\n",
      "Epoch 23: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 0.0116 - accuracy: 0.9963 - f1_score: 0.9674\n",
      "Epoch 24/50\n",
      "501/504 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9963 - f1_score: 0.9491\n",
      "Epoch 24: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0124 - accuracy: 0.9963 - f1_score: 0.9489\n",
      "Epoch 25/50\n",
      "500/504 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9964 - f1_score: 0.9459\n",
      "Epoch 25: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0115 - accuracy: 0.9964 - f1_score: 0.9461\n",
      "Epoch 26/50\n",
      "501/504 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9966 - f1_score: 0.9622\n",
      "Epoch 26: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0111 - accuracy: 0.9966 - f1_score: 0.9622\n",
      "Epoch 27/50\n",
      "503/504 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9966 - f1_score: 0.9655\n",
      "Epoch 27: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0106 - accuracy: 0.9966 - f1_score: 0.9655\n",
      "Epoch 28/50\n",
      "498/504 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9962 - f1_score: 0.9484\n",
      "Epoch 28: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 0.0137 - accuracy: 0.9961 - f1_score: 0.9487\n",
      "Epoch 29/50\n",
      "502/504 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9963 - f1_score: 0.9406\n",
      "Epoch 29: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 8ms/step - loss: 0.0136 - accuracy: 0.9963 - f1_score: 0.9407\n",
      "Epoch 30/50\n",
      "502/504 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9964 - f1_score: 0.9652\n",
      "Epoch 30: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0112 - accuracy: 0.9964 - f1_score: 0.9652\n",
      "Epoch 31/50\n",
      "500/504 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9968 - f1_score: 0.9681\n",
      "Epoch 31: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0102 - accuracy: 0.9967 - f1_score: 0.9679\n",
      "Epoch 32/50\n",
      "501/504 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9962 - f1_score: 0.9713\n",
      "Epoch 32: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0118 - accuracy: 0.9962 - f1_score: 0.9714\n",
      "Epoch 33/50\n",
      "500/504 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9967 - f1_score: 0.9434\n",
      "Epoch 33: accuracy did not improve from 0.99679\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0115 - accuracy: 0.9967 - f1_score: 0.9435\n",
      "Epoch 34/50\n",
      "499/504 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9971 - f1_score: 0.9414\n",
      "Epoch 34: accuracy improved from 0.99679 to 0.99716, saving model to ./batch_size-125\\wght-imprv-34-1.00-0.94.hdf5\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0103 - accuracy: 0.9972 - f1_score: 0.9414\n",
      "Epoch 35/50\n",
      "504/504 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9966 - f1_score: 0.9580\n",
      "Epoch 35: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0106 - accuracy: 0.9966 - f1_score: 0.9580\n",
      "Epoch 36/50\n",
      "502/504 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9969 - f1_score: 0.9607\n",
      "Epoch 36: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 0.0106 - accuracy: 0.9969 - f1_score: 0.9608\n",
      "Epoch 37/50\n",
      "497/504 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9970 - f1_score: 0.9751\n",
      "Epoch 37: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 0.0099 - accuracy: 0.9970 - f1_score: 0.9752\n",
      "Epoch 38/50\n",
      "498/504 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9964 - f1_score: 0.9652\n",
      "Epoch 38: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0121 - accuracy: 0.9964 - f1_score: 0.9649\n",
      "Epoch 39/50\n",
      "499/504 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9964 - f1_score: 0.9710\n",
      "Epoch 39: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0114 - accuracy: 0.9964 - f1_score: 0.9710\n",
      "Epoch 40/50\n",
      "501/504 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9967 - f1_score: 0.9749\n",
      "Epoch 40: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0105 - accuracy: 0.9967 - f1_score: 0.9748\n",
      "Epoch 41/50\n",
      "501/504 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9967 - f1_score: 0.9650\n",
      "Epoch 41: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0113 - accuracy: 0.9967 - f1_score: 0.9647\n",
      "Epoch 42/50\n",
      "499/504 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9967 - f1_score: 0.9567\n",
      "Epoch 42: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0108 - accuracy: 0.9967 - f1_score: 0.9566\n",
      "Epoch 43/50\n",
      "500/504 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9968 - f1_score: 0.9743\n",
      "Epoch 43: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 0.0101 - accuracy: 0.9968 - f1_score: 0.9742\n",
      "Epoch 44/50\n",
      "500/504 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9966 - f1_score: 0.9644\n",
      "Epoch 44: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0106 - accuracy: 0.9966 - f1_score: 0.9644\n",
      "Epoch 45/50\n",
      "503/504 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9969 - f1_score: 0.9790\n",
      "Epoch 45: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 0.0098 - accuracy: 0.9969 - f1_score: 0.9790\n",
      "Epoch 46/50\n",
      "501/504 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9964 - f1_score: 0.9300\n",
      "Epoch 46: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0147 - accuracy: 0.9965 - f1_score: 0.9301\n",
      "Epoch 47/50\n",
      "504/504 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9966 - f1_score: 0.9603\n",
      "Epoch 47: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0108 - accuracy: 0.9966 - f1_score: 0.9603\n",
      "Epoch 48/50\n",
      "504/504 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9970 - f1_score: 0.9755\n",
      "Epoch 48: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 6ms/step - loss: 0.0098 - accuracy: 0.9970 - f1_score: 0.9755\n",
      "Epoch 49/50\n",
      "503/504 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9967 - f1_score: 0.9713\n",
      "Epoch 49: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 3s 7ms/step - loss: 0.0116 - accuracy: 0.9967 - f1_score: 0.9713\n",
      "Epoch 50/50\n",
      "504/504 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9966 - f1_score: 0.9520\n",
      "Epoch 50: accuracy did not improve from 0.99716\n",
      "504/504 [==============================] - 4s 7ms/step - loss: 0.0110 - accuracy: 0.9966 - f1_score: 0.9520\n",
      "Epoch 1/50\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 0.3756 - accuracy: 0.7934 - f1_score: 0.7703\n",
      "Epoch 1: accuracy improved from -inf to 0.79591, saving model to ./batch_size-625\\wght-imprv-01-0.80-0.77.hdf5\n",
      "101/101 [==============================] - 2s 7ms/step - loss: 0.3716 - accuracy: 0.7959 - f1_score: 0.7704\n",
      "Epoch 2/50\n",
      "100/101 [============================>.] - ETA: 0s - loss: 0.0944 - accuracy: 0.9555 - f1_score: 0.7746\n",
      "Epoch 2: accuracy improved from 0.79591 to 0.95555, saving model to ./batch_size-625\\wght-imprv-02-0.96-0.77.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0942 - accuracy: 0.9556 - f1_score: 0.7748\n",
      "Epoch 3/50\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 0.0591 - accuracy: 0.9725 - f1_score: 0.7901\n",
      "Epoch 3: accuracy improved from 0.95555 to 0.97263, saving model to ./batch_size-625\\wght-imprv-03-0.97-0.79.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0590 - accuracy: 0.9726 - f1_score: 0.7908\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9783 - f1_score: 0.8209\n",
      "Epoch 4: accuracy improved from 0.97263 to 0.97828, saving model to ./batch_size-625\\wght-imprv-04-0.98-0.82.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0464 - accuracy: 0.9783 - f1_score: 0.8209\n",
      "Epoch 5/50\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9812 - f1_score: 0.8357\n",
      "Epoch 5: accuracy improved from 0.97828 to 0.98120, saving model to ./batch_size-625\\wght-imprv-05-0.98-0.84.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0414 - accuracy: 0.9812 - f1_score: 0.8351\n",
      "Epoch 6/50\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 0.0387 - accuracy: 0.9826 - f1_score: 0.8353\n",
      "Epoch 6: accuracy improved from 0.98120 to 0.98265, saving model to ./batch_size-625\\wght-imprv-06-0.98-0.84.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9826 - f1_score: 0.8353\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9853 - f1_score: 0.8472\n",
      "Epoch 7: accuracy improved from 0.98265 to 0.98532, saving model to ./batch_size-625\\wght-imprv-07-0.99-0.85.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0336 - accuracy: 0.9853 - f1_score: 0.8472\n",
      "Epoch 8/50\n",
      " 93/101 [==========================>...] - ETA: 0s - loss: 0.0301 - accuracy: 0.9903 - f1_score: 0.8811\n",
      "Epoch 8: accuracy improved from 0.98532 to 0.99025, saving model to ./batch_size-625\\wght-imprv-08-0.99-0.88.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0299 - accuracy: 0.9903 - f1_score: 0.8806\n",
      "Epoch 9/50\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 0.0271 - accuracy: 0.9918 - f1_score: 0.8842\n",
      "Epoch 9: accuracy improved from 0.99025 to 0.99178, saving model to ./batch_size-625\\wght-imprv-09-0.99-0.88.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0271 - accuracy: 0.9918 - f1_score: 0.8835\n",
      "Epoch 10/50\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9928 - f1_score: 0.8853\n",
      "Epoch 10: accuracy improved from 0.99178 to 0.99286, saving model to ./batch_size-625\\wght-imprv-10-0.99-0.89.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0251 - accuracy: 0.9929 - f1_score: 0.8857\n",
      "Epoch 11/50\n",
      " 96/101 [===========================>..] - ETA: 0s - loss: 0.0225 - accuracy: 0.9934 - f1_score: 0.9077\n",
      "Epoch 11: accuracy improved from 0.99286 to 0.99351, saving model to ./batch_size-625\\wght-imprv-11-0.99-0.91.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0224 - accuracy: 0.9935 - f1_score: 0.9073\n",
      "Epoch 12/50\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 0.0234 - accuracy: 0.9933 - f1_score: 0.9029\n",
      "Epoch 12: accuracy did not improve from 0.99351\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0233 - accuracy: 0.9933 - f1_score: 0.9030\n",
      "Epoch 13/50\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 0.0222 - accuracy: 0.9932 - f1_score: 0.9031\n",
      "Epoch 13: accuracy did not improve from 0.99351\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0219 - accuracy: 0.9932 - f1_score: 0.9033\n",
      "Epoch 14/50\n",
      "101/101 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9937 - f1_score: 0.9114\n",
      "Epoch 14: accuracy improved from 0.99351 to 0.99368, saving model to ./batch_size-625\\wght-imprv-14-0.99-0.91.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0207 - accuracy: 0.9937 - f1_score: 0.9114\n",
      "Epoch 15/50\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9941 - f1_score: 0.9224\n",
      "Epoch 15: accuracy improved from 0.99368 to 0.99411, saving model to ./batch_size-625\\wght-imprv-15-0.99-0.92.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0199 - accuracy: 0.9941 - f1_score: 0.9219\n",
      "Epoch 16/50\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 0.0199 - accuracy: 0.9940 - f1_score: 0.9238\n",
      "Epoch 16: accuracy did not improve from 0.99411\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0199 - accuracy: 0.9940 - f1_score: 0.9232\n",
      "Epoch 17/50\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9938 - f1_score: 0.9263\n",
      "Epoch 17: accuracy did not improve from 0.99411\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0198 - accuracy: 0.9938 - f1_score: 0.9259\n",
      "Epoch 18/50\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9941 - f1_score: 0.9369\n",
      "Epoch 18: accuracy did not improve from 0.99411\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0181 - accuracy: 0.9941 - f1_score: 0.9366\n",
      "Epoch 19/50\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9948 - f1_score: 0.9202\n",
      "Epoch 19: accuracy improved from 0.99411 to 0.99479, saving model to ./batch_size-625\\wght-imprv-19-0.99-0.92.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0196 - accuracy: 0.9948 - f1_score: 0.9206\n",
      "Epoch 20/50\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 0.0171 - accuracy: 0.9957 - f1_score: 0.9311\n",
      "Epoch 20: accuracy improved from 0.99479 to 0.99571, saving model to ./batch_size-625\\wght-imprv-20-1.00-0.93.hdf5\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0171 - accuracy: 0.9957 - f1_score: 0.9306\n",
      "Epoch 21/50\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9958 - f1_score: 0.9420\n",
      "Epoch 21: accuracy improved from 0.99571 to 0.99578, saving model to ./batch_size-625\\wght-imprv-21-1.00-0.94.hdf5\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 0.0154 - accuracy: 0.9958 - f1_score: 0.9422\n",
      "Epoch 22/50\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 0.0154 - accuracy: 0.9959 - f1_score: 0.9399\n",
      "Epoch 22: accuracy improved from 0.99578 to 0.99582, saving model to ./batch_size-625\\wght-imprv-22-1.00-0.94.hdf5\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 0.0154 - accuracy: 0.9958 - f1_score: 0.9391\n",
      "Epoch 23/50\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9959 - f1_score: 0.9464\n",
      "Epoch 23: accuracy improved from 0.99582 to 0.99594, saving model to ./batch_size-625\\wght-imprv-23-1.00-0.95.hdf5\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 0.0145 - accuracy: 0.9959 - f1_score: 0.9469\n",
      "Epoch 24/50\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9959 - f1_score: 0.9491\n",
      "Epoch 24: accuracy did not improve from 0.99594\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0146 - accuracy: 0.9959 - f1_score: 0.9492\n",
      "Epoch 25/50\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9957 - f1_score: 0.9251\n",
      "Epoch 25: accuracy did not improve from 0.99594\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0159 - accuracy: 0.9957 - f1_score: 0.9261\n",
      "Epoch 26/50\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 0.0137 - accuracy: 0.9965 - f1_score: 0.9306\n",
      "Epoch 26: accuracy improved from 0.99594 to 0.99651, saving model to ./batch_size-625\\wght-imprv-26-1.00-0.93.hdf5\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 0.0137 - accuracy: 0.9965 - f1_score: 0.9308\n",
      "Epoch 27/50\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9962 - f1_score: 0.9489\n",
      "Epoch 27: accuracy did not improve from 0.99651\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0134 - accuracy: 0.9962 - f1_score: 0.9489\n",
      "Epoch 28/50\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9960 - f1_score: 0.9555\n",
      "Epoch 28: accuracy did not improve from 0.99651\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0133 - accuracy: 0.9960 - f1_score: 0.9557\n",
      "Epoch 29/50\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9966 - f1_score: 0.9591\n",
      "Epoch 29: accuracy did not improve from 0.99651\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0129 - accuracy: 0.9965 - f1_score: 0.9591\n",
      "Epoch 30/50\n",
      " 96/101 [===========================>..] - ETA: 0s - loss: 0.0126 - accuracy: 0.9961 - f1_score: 0.9634\n",
      "Epoch 30: accuracy did not improve from 0.99651\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0125 - accuracy: 0.9962 - f1_score: 0.9638\n",
      "Epoch 31/50\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9959 - f1_score: 0.9595\n",
      "Epoch 31: accuracy did not improve from 0.99651\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0145 - accuracy: 0.9959 - f1_score: 0.9592\n",
      "Epoch 32/50\n",
      "100/101 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9961 - f1_score: 0.9594\n",
      "Epoch 32: accuracy did not improve from 0.99651\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0131 - accuracy: 0.9961 - f1_score: 0.9593\n",
      "Epoch 33/50\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 0.0128 - accuracy: 0.9965 - f1_score: 0.9513\n",
      "Epoch 33: accuracy did not improve from 0.99651\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0127 - accuracy: 0.9965 - f1_score: 0.9517\n",
      "Epoch 34/50\n",
      " 96/101 [===========================>..] - ETA: 0s - loss: 0.0120 - accuracy: 0.9965 - f1_score: 0.9677\n",
      "Epoch 34: accuracy did not improve from 0.99651\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0122 - accuracy: 0.9964 - f1_score: 0.9678\n",
      "Epoch 35/50\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 0.0105 - accuracy: 0.9970 - f1_score: 0.9727\n",
      "Epoch 35: accuracy improved from 0.99651 to 0.99692, saving model to ./batch_size-625\\wght-imprv-35-1.00-0.97.hdf5\n",
      "101/101 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.9969 - f1_score: 0.9730\n",
      "Epoch 36/50\n",
      " 98/101 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9965 - f1_score: 0.9761\n",
      "Epoch 36: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0115 - accuracy: 0.9965 - f1_score: 0.9763\n",
      "Epoch 37/50\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 0.0120 - accuracy: 0.9962 - f1_score: 0.9755\n",
      "Epoch 37: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0120 - accuracy: 0.9962 - f1_score: 0.9751\n",
      "Epoch 38/50\n",
      " 93/101 [==========================>...] - ETA: 0s - loss: 0.0121 - accuracy: 0.9964 - f1_score: 0.9607\n",
      "Epoch 38: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0120 - accuracy: 0.9964 - f1_score: 0.9612\n",
      "Epoch 39/50\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 0.0112 - accuracy: 0.9966 - f1_score: 0.9711\n",
      "Epoch 39: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0114 - accuracy: 0.9965 - f1_score: 0.9705\n",
      "Epoch 40/50\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 0.0103 - accuracy: 0.9968 - f1_score: 0.9824\n",
      "Epoch 40: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0102 - accuracy: 0.9968 - f1_score: 0.9826\n",
      "Epoch 41/50\n",
      " 96/101 [===========================>..] - ETA: 0s - loss: 0.0131 - accuracy: 0.9962 - f1_score: 0.9772\n",
      "Epoch 41: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0129 - accuracy: 0.9963 - f1_score: 0.9763\n",
      "Epoch 42/50\n",
      " 94/101 [==========================>...] - ETA: 0s - loss: 0.0118 - accuracy: 0.9962 - f1_score: 0.9633\n",
      "Epoch 42: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0118 - accuracy: 0.9963 - f1_score: 0.9638\n",
      "Epoch 43/50\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9964 - f1_score: 0.9754\n",
      "Epoch 43: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 6ms/step - loss: 0.0115 - accuracy: 0.9964 - f1_score: 0.9748\n",
      "Epoch 44/50\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9963 - f1_score: 0.9768\n",
      "Epoch 44: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0115 - accuracy: 0.9963 - f1_score: 0.9768\n",
      "Epoch 45/50\n",
      " 99/101 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9965 - f1_score: 0.9775\n",
      "Epoch 45: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0112 - accuracy: 0.9965 - f1_score: 0.9774\n",
      "Epoch 46/50\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 0.0112 - accuracy: 0.9966 - f1_score: 0.9748\n",
      "Epoch 46: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0111 - accuracy: 0.9967 - f1_score: 0.9746\n",
      "Epoch 47/50\n",
      " 95/101 [===========================>..] - ETA: 0s - loss: 0.0106 - accuracy: 0.9969 - f1_score: 0.9747\n",
      "Epoch 47: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0106 - accuracy: 0.9969 - f1_score: 0.9750\n",
      "Epoch 48/50\n",
      " 96/101 [===========================>..] - ETA: 0s - loss: 0.0110 - accuracy: 0.9966 - f1_score: 0.9789\n",
      "Epoch 48: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0109 - accuracy: 0.9967 - f1_score: 0.9778\n",
      "Epoch 49/50\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 0.0115 - accuracy: 0.9965 - f1_score: 0.9769\n",
      "Epoch 49: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0115 - accuracy: 0.9965 - f1_score: 0.9771\n",
      "Epoch 50/50\n",
      " 97/101 [===========================>..] - ETA: 0s - loss: 0.0103 - accuracy: 0.9968 - f1_score: 0.9825\n",
      "Epoch 50: accuracy did not improve from 0.99692\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.0101 - accuracy: 0.9969 - f1_score: 0.9826\n",
      "Epoch 1/50\n",
      "16/21 [=====================>........] - ETA: 0s - loss: 0.8740 - accuracy: 0.5586 - f1_score: 0.7705\n",
      "Epoch 1: accuracy improved from -inf to 0.56652, saving model to ./batch_size-3125\\wght-imprv-01-0.57-0.77.hdf5\n",
      "21/21 [==============================] - 1s 9ms/step - loss: 0.8376 - accuracy: 0.5665 - f1_score: 0.7703\n",
      "Epoch 2/50\n",
      "14/21 [===================>..........] - ETA: 0s - loss: 0.6642 - accuracy: 0.6232 - f1_score: 0.7697\n",
      "Epoch 2: accuracy improved from 0.56652 to 0.63336, saving model to ./batch_size-3125\\wght-imprv-02-0.63-0.77.hdf5\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.6497 - accuracy: 0.6334 - f1_score: 0.7703\n",
      "Epoch 3/50\n",
      "15/21 [====================>.........] - ETA: 0s - loss: 0.5290 - accuracy: 0.7151 - f1_score: 0.7705\n",
      "Epoch 3: accuracy improved from 0.63336 to 0.73456, saving model to ./batch_size-3125\\wght-imprv-03-0.73-0.77.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.5066 - accuracy: 0.7346 - f1_score: 0.7703\n",
      "Epoch 4/50\n",
      "15/21 [====================>.........] - ETA: 0s - loss: 0.3479 - accuracy: 0.8548 - f1_score: 0.7704\n",
      "Epoch 4: accuracy improved from 0.73456 to 0.86329, saving model to ./batch_size-3125\\wght-imprv-04-0.86-0.77.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.3323 - accuracy: 0.8633 - f1_score: 0.7706\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.9060 - f1_score: 0.7727\n",
      "Epoch 5: accuracy improved from 0.86329 to 0.90601, saving model to ./batch_size-3125\\wght-imprv-05-0.91-0.77.hdf5\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.2405 - accuracy: 0.9060 - f1_score: 0.7727\n",
      "Epoch 6/50\n",
      "17/21 [=======================>......] - ETA: 0s - loss: 0.2027 - accuracy: 0.9278 - f1_score: 0.7812\n",
      "Epoch 6: accuracy improved from 0.90601 to 0.92845, saving model to ./batch_size-3125\\wght-imprv-06-0.93-0.78.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.2000 - accuracy: 0.9285 - f1_score: 0.7814\n",
      "Epoch 7/50\n",
      "17/21 [=======================>......] - ETA: 0s - loss: 0.1701 - accuracy: 0.9431 - f1_score: 0.7945\n",
      "Epoch 7: accuracy improved from 0.92845 to 0.94339, saving model to ./batch_size-3125\\wght-imprv-07-0.94-0.80.hdf5\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.1685 - accuracy: 0.9434 - f1_score: 0.7952\n",
      "Epoch 8/50\n",
      "16/21 [=====================>........] - ETA: 0s - loss: 0.1501 - accuracy: 0.9587 - f1_score: 0.8105\n",
      "Epoch 8: accuracy improved from 0.94339 to 0.95988, saving model to ./batch_size-3125\\wght-imprv-08-0.96-0.81.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.1493 - accuracy: 0.9599 - f1_score: 0.8138\n",
      "Epoch 9/50\n",
      "16/21 [=====================>........] - ETA: 0s - loss: 0.1385 - accuracy: 0.9672 - f1_score: 0.8259\n",
      "Epoch 9: accuracy improved from 0.95988 to 0.96746, saving model to ./batch_size-3125\\wght-imprv-09-0.97-0.83.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.1378 - accuracy: 0.9675 - f1_score: 0.8275\n",
      "Epoch 10/50\n",
      "16/21 [=====================>........] - ETA: 0s - loss: 0.1317 - accuracy: 0.9751 - f1_score: 0.8340\n",
      "Epoch 10: accuracy improved from 0.96746 to 0.97604, saving model to ./batch_size-3125\\wght-imprv-10-0.98-0.84.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.1303 - accuracy: 0.9760 - f1_score: 0.8360\n",
      "Epoch 11/50\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.1122 - accuracy: 0.9818 - f1_score: 0.8437\n",
      "Epoch 11: accuracy improved from 0.97604 to 0.98182, saving model to ./batch_size-3125\\wght-imprv-11-0.98-0.84.hdf5\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.1120 - accuracy: 0.9818 - f1_score: 0.8436\n",
      "Epoch 12/50\n",
      "17/21 [=======================>......] - ETA: 0s - loss: 0.0827 - accuracy: 0.9865 - f1_score: 0.8514\n",
      "Epoch 12: accuracy improved from 0.98182 to 0.98694, saving model to ./batch_size-3125\\wght-imprv-12-0.99-0.85.hdf5\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9869 - f1_score: 0.8522\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9909 - f1_score: 0.8536\n",
      "Epoch 13: accuracy improved from 0.98694 to 0.99090, saving model to ./batch_size-3125\\wght-imprv-13-0.99-0.85.hdf5\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.0736 - accuracy: 0.9909 - f1_score: 0.8536\n",
      "Epoch 14/50\n",
      "15/21 [====================>.........] - ETA: 0s - loss: 0.0716 - accuracy: 0.9912 - f1_score: 0.8514\n",
      "Epoch 14: accuracy improved from 0.99090 to 0.99128, saving model to ./batch_size-3125\\wght-imprv-14-0.99-0.85.hdf5\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.0700 - accuracy: 0.9913 - f1_score: 0.8513\n",
      "Epoch 15/50\n",
      "15/21 [====================>.........] - ETA: 0s - loss: 0.0664 - accuracy: 0.9923 - f1_score: 0.8606\n",
      "Epoch 15: accuracy improved from 0.99128 to 0.99205, saving model to ./batch_size-3125\\wght-imprv-15-0.99-0.86.hdf5\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.0652 - accuracy: 0.9920 - f1_score: 0.8565\n",
      "Epoch 16/50\n",
      "16/21 [=====================>........] - ETA: 0s - loss: 0.0578 - accuracy: 0.9932 - f1_score: 0.8532\n",
      "Epoch 16: accuracy improved from 0.99205 to 0.99309, saving model to ./batch_size-3125\\wght-imprv-16-0.99-0.85.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0567 - accuracy: 0.9931 - f1_score: 0.8517\n",
      "Epoch 17/50\n",
      "15/21 [====================>.........] - ETA: 0s - loss: 0.0531 - accuracy: 0.9934 - f1_score: 0.8527\n",
      "Epoch 17: accuracy improved from 0.99309 to 0.99352, saving model to ./batch_size-3125\\wght-imprv-17-0.99-0.86.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0531 - accuracy: 0.9935 - f1_score: 0.8568\n",
      "Epoch 18/50\n",
      "16/21 [=====================>........] - ETA: 0s - loss: 0.0527 - accuracy: 0.9939 - f1_score: 0.8606\n",
      "Epoch 18: accuracy improved from 0.99352 to 0.99400, saving model to ./batch_size-3125\\wght-imprv-18-0.99-0.86.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0514 - accuracy: 0.9940 - f1_score: 0.8614\n",
      "Epoch 19/50\n",
      "17/21 [=======================>......] - ETA: 0s - loss: 0.0470 - accuracy: 0.9941 - f1_score: 0.8585\n",
      "Epoch 19: accuracy improved from 0.99400 to 0.99422, saving model to ./batch_size-3125\\wght-imprv-19-0.99-0.86.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0465 - accuracy: 0.9942 - f1_score: 0.8591\n",
      "Epoch 20/50\n",
      "17/21 [=======================>......] - ETA: 0s - loss: 0.0432 - accuracy: 0.9944 - f1_score: 0.8681\n",
      "Epoch 20: accuracy improved from 0.99422 to 0.99433, saving model to ./batch_size-3125\\wght-imprv-20-0.99-0.87.hdf5\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.0436 - accuracy: 0.9943 - f1_score: 0.8678\n",
      "Epoch 21/50\n",
      "16/21 [=====================>........] - ETA: 0s - loss: 0.0423 - accuracy: 0.9945 - f1_score: 0.8514\n",
      "Epoch 21: accuracy improved from 0.99433 to 0.99449, saving model to ./batch_size-3125\\wght-imprv-21-0.99-0.85.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0426 - accuracy: 0.9945 - f1_score: 0.8501\n",
      "Epoch 22/50\n",
      "17/21 [=======================>......] - ETA: 0s - loss: 0.0396 - accuracy: 0.9948 - f1_score: 0.8498\n",
      "Epoch 22: accuracy improved from 0.99449 to 0.99481, saving model to ./batch_size-3125\\wght-imprv-22-0.99-0.85.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0398 - accuracy: 0.9948 - f1_score: 0.8514\n",
      "Epoch 23/50\n",
      "15/21 [====================>.........] - ETA: 0s - loss: 0.0381 - accuracy: 0.9941 - f1_score: 0.8576\n",
      "Epoch 23: accuracy did not improve from 0.99481\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0385 - accuracy: 0.9944 - f1_score: 0.8605\n",
      "Epoch 24/50\n",
      "16/21 [=====================>........] - ETA: 0s - loss: 0.0366 - accuracy: 0.9953 - f1_score: 0.8778\n",
      "Epoch 24: accuracy improved from 0.99481 to 0.99517, saving model to ./batch_size-3125\\wght-imprv-24-1.00-0.88.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0366 - accuracy: 0.9952 - f1_score: 0.8788\n",
      "Epoch 25/50\n",
      "15/21 [====================>.........] - ETA: 0s - loss: 0.0364 - accuracy: 0.9955 - f1_score: 0.8841\n",
      "Epoch 25: accuracy improved from 0.99517 to 0.99568, saving model to ./batch_size-3125\\wght-imprv-25-1.00-0.89.hdf5\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.0364 - accuracy: 0.9957 - f1_score: 0.8858\n",
      "Epoch 26/50\n",
      "16/21 [=====================>........] - ETA: 0s - loss: 0.0365 - accuracy: 0.9955 - f1_score: 0.8753\n",
      "Epoch 26: accuracy did not improve from 0.99568\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9953 - f1_score: 0.8743\n",
      "Epoch 27/50\n",
      "16/21 [=====================>........] - ETA: 0s - loss: 0.0381 - accuracy: 0.9952 - f1_score: 0.8829\n",
      "Epoch 27: accuracy did not improve from 0.99568\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9951 - f1_score: 0.8781\n",
      "Epoch 28/50\n",
      "14/21 [===================>..........] - ETA: 0s - loss: 0.0384 - accuracy: 0.9945 - f1_score: 0.8543\n",
      "Epoch 28: accuracy did not improve from 0.99568\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0369 - accuracy: 0.9951 - f1_score: 0.8587\n",
      "Epoch 29/50\n",
      "18/21 [========================>.....] - ETA: 0s - loss: 0.0352 - accuracy: 0.9952 - f1_score: 0.8689\n",
      "Epoch 29: accuracy did not improve from 0.99568\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0351 - accuracy: 0.9951 - f1_score: 0.8712\n",
      "Epoch 30/50\n",
      "17/21 [=======================>......] - ETA: 0s - loss: 0.0335 - accuracy: 0.9956 - f1_score: 0.8810\n",
      "Epoch 30: accuracy did not improve from 0.99568\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9956 - f1_score: 0.8842\n",
      "Epoch 31/50\n",
      "15/21 [====================>.........] - ETA: 0s - loss: 0.0339 - accuracy: 0.9955 - f1_score: 0.8987\n",
      "Epoch 31: accuracy did not improve from 0.99568\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0336 - accuracy: 0.9953 - f1_score: 0.8952\n",
      "Epoch 32/50\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.0342 - accuracy: 0.9955 - f1_score: 0.8993\n",
      "Epoch 32: accuracy did not improve from 0.99568\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 0.9955 - f1_score: 0.8992\n",
      "Epoch 33/50\n",
      "15/21 [====================>.........] - ETA: 0s - loss: 0.0336 - accuracy: 0.9958 - f1_score: 0.8930\n",
      "Epoch 33: accuracy improved from 0.99568 to 0.99570, saving model to ./batch_size-3125\\wght-imprv-33-1.00-0.90.hdf5\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.0332 - accuracy: 0.9957 - f1_score: 0.8957\n",
      "Epoch 34/50\n",
      "15/21 [====================>.........] - ETA: 0s - loss: 0.0317 - accuracy: 0.9965 - f1_score: 0.9056\n",
      "Epoch 34: accuracy improved from 0.99570 to 0.99617, saving model to ./batch_size-3125\\wght-imprv-34-1.00-0.90.hdf5\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0322 - accuracy: 0.9962 - f1_score: 0.9032\n",
      "Epoch 35/50\n",
      "16/21 [=====================>........] - ETA: 0s - loss: 0.0323 - accuracy: 0.9954 - f1_score: 0.8972\n",
      "Epoch 35: accuracy did not improve from 0.99617\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9955 - f1_score: 0.8979\n",
      "Epoch 36/50\n",
      "15/21 [====================>.........] - ETA: 0s - loss: 0.0318 - accuracy: 0.9958 - f1_score: 0.9064\n",
      "Epoch 36: accuracy did not improve from 0.99617\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9959 - f1_score: 0.9055\n",
      "Epoch 37/50\n",
      "15/21 [====================>.........] - ETA: 0s - loss: 0.0295 - accuracy: 0.9968 - f1_score: 0.9180\n",
      "Epoch 37: accuracy improved from 0.99617 to 0.99660, saving model to ./batch_size-3125\\wght-imprv-37-1.00-0.92.hdf5\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.0298 - accuracy: 0.9966 - f1_score: 0.9165\n",
      "Epoch 38/50\n",
      "17/21 [=======================>......] - ETA: 0s - loss: 0.0319 - accuracy: 0.9957 - f1_score: 0.9056\n",
      "Epoch 38: accuracy did not improve from 0.99660\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 0.9958 - f1_score: 0.9053\n",
      "Epoch 39/50\n",
      "18/21 [========================>.....] - ETA: 0s - loss: 0.0318 - accuracy: 0.9959 - f1_score: 0.9133\n",
      "Epoch 39: accuracy did not improve from 0.99660\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0315 - accuracy: 0.9961 - f1_score: 0.9114\n",
      "Epoch 40/50\n",
      "17/21 [=======================>......] - ETA: 0s - loss: 0.0314 - accuracy: 0.9961 - f1_score: 0.9003\n",
      "Epoch 40: accuracy did not improve from 0.99660\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9960 - f1_score: 0.9016\n",
      "Epoch 41/50\n",
      "17/21 [=======================>......] - ETA: 0s - loss: 0.0299 - accuracy: 0.9963 - f1_score: 0.9046\n",
      "Epoch 41: accuracy did not improve from 0.99660\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9964 - f1_score: 0.9055\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9962 - f1_score: 0.9069\n",
      "Epoch 42: accuracy did not improve from 0.99660\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9962 - f1_score: 0.9069\n",
      "Epoch 43/50\n",
      "14/21 [===================>..........] - ETA: 0s - loss: 0.0291 - accuracy: 0.9962 - f1_score: 0.9282\n",
      "Epoch 43: accuracy did not improve from 0.99660\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 0.9960 - f1_score: 0.9245\n",
      "Epoch 44/50\n",
      "18/21 [========================>.....] - ETA: 0s - loss: 0.0294 - accuracy: 0.9961 - f1_score: 0.9184\n",
      "Epoch 44: accuracy did not improve from 0.99660\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0296 - accuracy: 0.9959 - f1_score: 0.9182\n",
      "Epoch 45/50\n",
      "17/21 [=======================>......] - ETA: 0s - loss: 0.0296 - accuracy: 0.9961 - f1_score: 0.9160\n",
      "Epoch 45: accuracy did not improve from 0.99660\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9963 - f1_score: 0.9179\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9961 - f1_score: 0.9185\n",
      "Epoch 46: accuracy did not improve from 0.99660\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9961 - f1_score: 0.9185\n",
      "Epoch 47/50\n",
      "15/21 [====================>.........] - ETA: 0s - loss: 0.0285 - accuracy: 0.9962 - f1_score: 0.9194\n",
      "Epoch 47: accuracy did not improve from 0.99660\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.9961 - f1_score: 0.9215\n",
      "Epoch 48/50\n",
      "17/21 [=======================>......] - ETA: 0s - loss: 0.0273 - accuracy: 0.9963 - f1_score: 0.9274\n",
      "Epoch 48: accuracy did not improve from 0.99660\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9963 - f1_score: 0.9266\n",
      "Epoch 49/50\n",
      "16/21 [=====================>........] - ETA: 0s - loss: 0.0276 - accuracy: 0.9966 - f1_score: 0.9270\n",
      "Epoch 49: accuracy did not improve from 0.99660\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9966 - f1_score: 0.9292\n",
      "Epoch 50/50\n",
      "17/21 [=======================>......] - ETA: 0s - loss: 0.0283 - accuracy: 0.9959 - f1_score: 0.9184\n",
      "Epoch 50: accuracy did not improve from 0.99660\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9958 - f1_score: 0.9183\n",
      "Epoch 1/50\n",
      "1/5 [=====>........................] - ETA: 3s - loss: 4.1258 - accuracy: 0.4258 - f1_score: 0.7647\n",
      "Epoch 1: accuracy improved from -inf to 0.46008, saving model to ./batch_size-15625\\wght-imprv-01-0.46-0.77.hdf5\n",
      "5/5 [==============================] - 1s 18ms/step - loss: 2.6504 - accuracy: 0.4601 - f1_score: 0.7694\n",
      "Epoch 2/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1293 - accuracy: 0.5123 - f1_score: 0.7743\n",
      "Epoch 2: accuracy improved from 0.46008 to 0.52425, saving model to ./batch_size-15625\\wght-imprv-02-0.52-0.77.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.9826 - accuracy: 0.5242 - f1_score: 0.7703\n",
      "Epoch 3/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.8317 - accuracy: 0.5329 - f1_score: 0.7671\n",
      "Epoch 3: accuracy improved from 0.52425 to 0.53639, saving model to ./batch_size-15625\\wght-imprv-03-0.54-0.77.hdf5\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.8175 - accuracy: 0.5364 - f1_score: 0.7703\n",
      "Epoch 4/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.7732 - accuracy: 0.5524 - f1_score: 0.7675\n",
      "Epoch 4: accuracy improved from 0.53639 to 0.55324, saving model to ./batch_size-15625\\wght-imprv-04-0.55-0.77.hdf5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7630 - accuracy: 0.5532 - f1_score: 0.7703\n",
      "Epoch 5/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.7349 - accuracy: 0.5562 - f1_score: 0.7709\n",
      "Epoch 5: accuracy improved from 0.55324 to 0.56505, saving model to ./batch_size-15625\\wght-imprv-05-0.57-0.77.hdf5\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.7218 - accuracy: 0.5650 - f1_score: 0.7703\n",
      "Epoch 6/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6970 - accuracy: 0.5766 - f1_score: 0.7675\n",
      "Epoch 6: accuracy improved from 0.56505 to 0.58378, saving model to ./batch_size-15625\\wght-imprv-06-0.58-0.77.hdf5\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6860 - accuracy: 0.5838 - f1_score: 0.7703\n",
      "Epoch 7/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6733 - accuracy: 0.5864 - f1_score: 0.7688\n",
      "Epoch 7: accuracy improved from 0.58378 to 0.59469, saving model to ./batch_size-15625\\wght-imprv-07-0.59-0.77.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6676 - accuracy: 0.5947 - f1_score: 0.7703\n",
      "Epoch 8/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6553 - accuracy: 0.6035 - f1_score: 0.7698\n",
      "Epoch 8: accuracy improved from 0.59469 to 0.60673, saving model to ./batch_size-15625\\wght-imprv-08-0.61-0.77.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6478 - accuracy: 0.6067 - f1_score: 0.7703\n",
      "Epoch 9/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6223 - accuracy: 0.6255 - f1_score: 0.7763\n",
      "Epoch 9: accuracy improved from 0.60673 to 0.62805, saving model to ./batch_size-15625\\wght-imprv-09-0.63-0.77.hdf5\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6201 - accuracy: 0.6281 - f1_score: 0.7703\n",
      "Epoch 10/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5971 - accuracy: 0.6406 - f1_score: 0.7723\n",
      "Epoch 10: accuracy improved from 0.62805 to 0.65504, saving model to ./batch_size-15625\\wght-imprv-10-0.66-0.77.hdf5\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5874 - accuracy: 0.6550 - f1_score: 0.7703\n",
      "Epoch 11/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5603 - accuracy: 0.6791 - f1_score: 0.7669\n",
      "Epoch 11: accuracy improved from 0.65504 to 0.69051, saving model to ./batch_size-15625\\wght-imprv-11-0.69-0.77.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5464 - accuracy: 0.6905 - f1_score: 0.7703\n",
      "Epoch 12/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.5169 - accuracy: 0.7123 - f1_score: 0.7707\n",
      "Epoch 12: accuracy improved from 0.69051 to 0.71860, saving model to ./batch_size-15625\\wght-imprv-12-0.72-0.77.hdf5\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5071 - accuracy: 0.7186 - f1_score: 0.7703\n",
      "Epoch 13/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4757 - accuracy: 0.7416 - f1_score: 0.7759\n",
      "Epoch 13: accuracy improved from 0.71860 to 0.74692, saving model to ./batch_size-15625\\wght-imprv-13-0.75-0.77.hdf5\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.4672 - accuracy: 0.7469 - f1_score: 0.7703\n",
      "Epoch 14/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4443 - accuracy: 0.7651 - f1_score: 0.7716\n",
      "Epoch 14: accuracy improved from 0.74692 to 0.77805, saving model to ./batch_size-15625\\wght-imprv-14-0.78-0.77.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.4293 - accuracy: 0.7781 - f1_score: 0.7703\n",
      "Epoch 15/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.4018 - accuracy: 0.8032 - f1_score: 0.7728\n",
      "Epoch 15: accuracy improved from 0.77805 to 0.81338, saving model to ./batch_size-15625\\wght-imprv-15-0.81-0.77.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3908 - accuracy: 0.8134 - f1_score: 0.7703\n",
      "Epoch 16/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3591 - accuracy: 0.8319 - f1_score: 0.7706\n",
      "Epoch 16: accuracy improved from 0.81338 to 0.84236, saving model to ./batch_size-15625\\wght-imprv-16-0.84-0.77.hdf5\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.3559 - accuracy: 0.8424 - f1_score: 0.7703\n",
      "Epoch 17/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3388 - accuracy: 0.8568 - f1_score: 0.7710\n",
      "Epoch 17: accuracy improved from 0.84236 to 0.86749, saving model to ./batch_size-15625\\wght-imprv-17-0.87-0.77.hdf5\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.3261 - accuracy: 0.8675 - f1_score: 0.7703\n",
      "Epoch 18/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.3081 - accuracy: 0.8840 - f1_score: 0.7730\n",
      "Epoch 18: accuracy improved from 0.86749 to 0.88953, saving model to ./batch_size-15625\\wght-imprv-18-0.89-0.77.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3041 - accuracy: 0.8895 - f1_score: 0.7703\n",
      "Epoch 19/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2811 - accuracy: 0.9048 - f1_score: 0.7725\n",
      "Epoch 19: accuracy improved from 0.88953 to 0.90650, saving model to ./batch_size-15625\\wght-imprv-19-0.91-0.77.hdf5\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2801 - accuracy: 0.9065 - f1_score: 0.7703\n",
      "Epoch 20/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2673 - accuracy: 0.9132 - f1_score: 0.7674\n",
      "Epoch 20: accuracy improved from 0.90650 to 0.91561, saving model to ./batch_size-15625\\wght-imprv-20-0.92-0.77.hdf5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.2640 - accuracy: 0.9156 - f1_score: 0.7704\n",
      "Epoch 21/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2471 - accuracy: 0.9245 - f1_score: 0.7707\n",
      "Epoch 21: accuracy improved from 0.91561 to 0.92894, saving model to ./batch_size-15625\\wght-imprv-21-0.93-0.77.hdf5\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.2454 - accuracy: 0.9289 - f1_score: 0.7705\n",
      "Epoch 22/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2390 - accuracy: 0.9324 - f1_score: 0.7699\n",
      "Epoch 22: accuracy improved from 0.92894 to 0.93321, saving model to ./batch_size-15625\\wght-imprv-22-0.93-0.77.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2370 - accuracy: 0.9332 - f1_score: 0.7707\n",
      "Epoch 23/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2256 - accuracy: 0.9374 - f1_score: 0.7703\n",
      "Epoch 23: accuracy improved from 0.93321 to 0.93955, saving model to ./batch_size-15625\\wght-imprv-23-0.94-0.77.hdf5\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2239 - accuracy: 0.9395 - f1_score: 0.7713\n",
      "Epoch 24/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2155 - accuracy: 0.9448 - f1_score: 0.7725\n",
      "Epoch 24: accuracy improved from 0.93955 to 0.94501, saving model to ./batch_size-15625\\wght-imprv-24-0.95-0.77.hdf5\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2143 - accuracy: 0.9450 - f1_score: 0.7714\n",
      "Epoch 25/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2112 - accuracy: 0.9443 - f1_score: 0.7746\n",
      "Epoch 25: accuracy improved from 0.94501 to 0.94836, saving model to ./batch_size-15625\\wght-imprv-25-0.95-0.77.hdf5\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.2074 - accuracy: 0.9484 - f1_score: 0.7716\n",
      "Epoch 26/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.2022 - accuracy: 0.9533 - f1_score: 0.7761\n",
      "Epoch 26: accuracy improved from 0.94836 to 0.95387, saving model to ./batch_size-15625\\wght-imprv-26-0.95-0.77.hdf5\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1971 - accuracy: 0.9539 - f1_score: 0.7728\n",
      "Epoch 27/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1909 - accuracy: 0.9560 - f1_score: 0.7688\n",
      "Epoch 27: accuracy improved from 0.95387 to 0.95731, saving model to ./batch_size-15625\\wght-imprv-27-0.96-0.77.hdf5\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1911 - accuracy: 0.9573 - f1_score: 0.7745\n",
      "Epoch 28/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1894 - accuracy: 0.9615 - f1_score: 0.7754\n",
      "Epoch 28: accuracy improved from 0.95731 to 0.96304, saving model to ./batch_size-15625\\wght-imprv-28-0.96-0.78.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1861 - accuracy: 0.9630 - f1_score: 0.7756\n",
      "Epoch 29/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1753 - accuracy: 0.9653 - f1_score: 0.7774\n",
      "Epoch 29: accuracy improved from 0.96304 to 0.96322, saving model to ./batch_size-15625\\wght-imprv-29-0.96-0.78.hdf5\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1764 - accuracy: 0.9632 - f1_score: 0.7773\n",
      "Epoch 30/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1660 - accuracy: 0.9641 - f1_score: 0.7767\n",
      "Epoch 30: accuracy improved from 0.96322 to 0.96454, saving model to ./batch_size-15625\\wght-imprv-30-0.96-0.78.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1630 - accuracy: 0.9645 - f1_score: 0.7796\n",
      "Epoch 31/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1523 - accuracy: 0.9641 - f1_score: 0.7822\n",
      "Epoch 31: accuracy did not improve from 0.96454\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1442 - accuracy: 0.9641 - f1_score: 0.7825\n",
      "Epoch 32/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1225 - accuracy: 0.9676 - f1_score: 0.7815\n",
      "Epoch 32: accuracy did not improve from 0.96454\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1267 - accuracy: 0.9633 - f1_score: 0.7823\n",
      "Epoch 33/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1283 - accuracy: 0.9619 - f1_score: 0.7858\n",
      "Epoch 33: accuracy did not improve from 0.96454\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1183 - accuracy: 0.9637 - f1_score: 0.7888\n",
      "Epoch 34/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1088 - accuracy: 0.9642 - f1_score: 0.7862\n",
      "Epoch 34: accuracy improved from 0.96454 to 0.96562, saving model to ./batch_size-15625\\wght-imprv-34-0.97-0.79.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1063 - accuracy: 0.9656 - f1_score: 0.7867\n",
      "Epoch 35/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.1034 - accuracy: 0.9643 - f1_score: 0.7818\n",
      "Epoch 35: accuracy improved from 0.96562 to 0.96755, saving model to ./batch_size-15625\\wght-imprv-35-0.97-0.78.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0979 - accuracy: 0.9676 - f1_score: 0.7835\n",
      "Epoch 36/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0914 - accuracy: 0.9718 - f1_score: 0.7847\n",
      "Epoch 36: accuracy improved from 0.96755 to 0.97333, saving model to ./batch_size-15625\\wght-imprv-36-0.97-0.79.hdf5\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0873 - accuracy: 0.9733 - f1_score: 0.7898\n",
      "Epoch 37/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0842 - accuracy: 0.9740 - f1_score: 0.7917\n",
      "Epoch 37: accuracy improved from 0.97333 to 0.97614, saving model to ./batch_size-15625\\wght-imprv-37-0.98-0.79.hdf5\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0807 - accuracy: 0.9761 - f1_score: 0.7892\n",
      "Epoch 38/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0778 - accuracy: 0.9746 - f1_score: 0.7852\n",
      "Epoch 38: accuracy improved from 0.97614 to 0.97628, saving model to ./batch_size-15625\\wght-imprv-38-0.98-0.79.hdf5\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0754 - accuracy: 0.9763 - f1_score: 0.7895\n",
      "Epoch 39/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0705 - accuracy: 0.9788 - f1_score: 0.7938\n",
      "Epoch 39: accuracy improved from 0.97628 to 0.97935, saving model to ./batch_size-15625\\wght-imprv-39-0.98-0.79.hdf5\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0680 - accuracy: 0.9793 - f1_score: 0.7927\n",
      "Epoch 40/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0676 - accuracy: 0.9786 - f1_score: 0.7960\n",
      "Epoch 40: accuracy improved from 0.97935 to 0.97962, saving model to ./batch_size-15625\\wght-imprv-40-0.98-0.79.hdf5\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0666 - accuracy: 0.9796 - f1_score: 0.7931\n",
      "Epoch 41/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0638 - accuracy: 0.9796 - f1_score: 0.7923\n",
      "Epoch 41: accuracy improved from 0.97962 to 0.97990, saving model to ./batch_size-15625\\wght-imprv-41-0.98-0.80.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0649 - accuracy: 0.9799 - f1_score: 0.7990\n",
      "Epoch 42/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0679 - accuracy: 0.9796 - f1_score: 0.7955\n",
      "Epoch 42: accuracy improved from 0.97990 to 0.98111, saving model to ./batch_size-15625\\wght-imprv-42-0.98-0.80.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0632 - accuracy: 0.9811 - f1_score: 0.7975\n",
      "Epoch 43/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0597 - accuracy: 0.9811 - f1_score: 0.8016\n",
      "Epoch 43: accuracy improved from 0.98111 to 0.98176, saving model to ./batch_size-15625\\wght-imprv-43-0.98-0.80.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0606 - accuracy: 0.9818 - f1_score: 0.7965\n",
      "Epoch 44/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0614 - accuracy: 0.9819 - f1_score: 0.7974\n",
      "Epoch 44: accuracy improved from 0.98176 to 0.98301, saving model to ./batch_size-15625\\wght-imprv-44-0.98-0.80.hdf5\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0570 - accuracy: 0.9830 - f1_score: 0.8034\n",
      "Epoch 45/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0506 - accuracy: 0.9852 - f1_score: 0.8027\n",
      "Epoch 45: accuracy improved from 0.98301 to 0.98459, saving model to ./batch_size-15625\\wght-imprv-45-0.98-0.80.hdf5\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0539 - accuracy: 0.9846 - f1_score: 0.8029\n",
      "Epoch 46/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0499 - accuracy: 0.9832 - f1_score: 0.7995\n",
      "Epoch 46: accuracy did not improve from 0.98459\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0520 - accuracy: 0.9831 - f1_score: 0.8007\n",
      "Epoch 47/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0492 - accuracy: 0.9853 - f1_score: 0.8051\n",
      "Epoch 47: accuracy did not improve from 0.98459\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0527 - accuracy: 0.9841 - f1_score: 0.8115\n",
      "Epoch 48/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0513 - accuracy: 0.9846 - f1_score: 0.8143\n",
      "Epoch 48: accuracy improved from 0.98459 to 0.98495, saving model to ./batch_size-15625\\wght-imprv-48-0.98-0.81.hdf5\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0516 - accuracy: 0.9850 - f1_score: 0.8150\n",
      "Epoch 49/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0475 - accuracy: 0.9850 - f1_score: 0.8050\n",
      "Epoch 49: accuracy did not improve from 0.98495\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0508 - accuracy: 0.9840 - f1_score: 0.8070\n",
      "Epoch 50/50\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0500 - accuracy: 0.9853 - f1_score: 0.8082\n",
      "Epoch 50: accuracy did not improve from 0.98495\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 0.9849 - f1_score: 0.8112\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.3345 - accuracy: 0.4725 - f1_score: 0.7698\n",
      "Epoch 1: accuracy improved from -inf to 0.47250, saving model to ./batch_size-62993\\wght-imprv-01-0.47-0.77.hdf5\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 2.3345 - accuracy: 0.4725 - f1_score: 0.7698\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6138 - accuracy: 0.5269 - f1_score: 0.7703\n",
      "Epoch 2: accuracy improved from 0.47250 to 0.52693, saving model to ./batch_size-62993\\wght-imprv-02-0.53-0.77.hdf5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.6138 - accuracy: 0.5269 - f1_score: 0.7703\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2733 - accuracy: 0.5465 - f1_score: 0.7703\n",
      "Epoch 3: accuracy improved from 0.52693 to 0.54646, saving model to ./batch_size-62993\\wght-imprv-03-0.55-0.77.hdf5\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.2733 - accuracy: 0.5465 - f1_score: 0.7703\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0629 - accuracy: 0.5618 - f1_score: 0.7703\n",
      "Epoch 4: accuracy improved from 0.54646 to 0.56184, saving model to ./batch_size-62993\\wght-imprv-04-0.56-0.77.hdf5\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.0629 - accuracy: 0.5618 - f1_score: 0.7703\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9502 - accuracy: 0.5680 - f1_score: 0.7703\n",
      "Epoch 5: accuracy improved from 0.56184 to 0.56798, saving model to ./batch_size-62993\\wght-imprv-05-0.57-0.77.hdf5\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9502 - accuracy: 0.5680 - f1_score: 0.7703\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8759 - accuracy: 0.5729 - f1_score: 0.7703\n",
      "Epoch 6: accuracy improved from 0.56798 to 0.57286, saving model to ./batch_size-62993\\wght-imprv-06-0.57-0.77.hdf5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.8759 - accuracy: 0.5729 - f1_score: 0.7703\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8180 - accuracy: 0.5787 - f1_score: 0.7703\n",
      "Epoch 7: accuracy improved from 0.57286 to 0.57873, saving model to ./batch_size-62993\\wght-imprv-07-0.58-0.77.hdf5\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.8180 - accuracy: 0.5787 - f1_score: 0.7703\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7861 - accuracy: 0.5803 - f1_score: 0.7703\n",
      "Epoch 8: accuracy improved from 0.57873 to 0.58029, saving model to ./batch_size-62993\\wght-imprv-08-0.58-0.77.hdf5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7861 - accuracy: 0.5803 - f1_score: 0.7703\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7602 - accuracy: 0.5800 - f1_score: 0.7703\n",
      "Epoch 9: accuracy did not improve from 0.58029\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7602 - accuracy: 0.5800 - f1_score: 0.7703\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7406 - accuracy: 0.5841 - f1_score: 0.7703\n",
      "Epoch 10: accuracy improved from 0.58029 to 0.58410, saving model to ./batch_size-62993\\wght-imprv-10-0.58-0.77.hdf5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7406 - accuracy: 0.5841 - f1_score: 0.7703\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7328 - accuracy: 0.5806 - f1_score: 0.7703\n",
      "Epoch 11: accuracy did not improve from 0.58410\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7328 - accuracy: 0.5806 - f1_score: 0.7703\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7177 - accuracy: 0.5861 - f1_score: 0.7703\n",
      "Epoch 12: accuracy improved from 0.58410 to 0.58608, saving model to ./batch_size-62993\\wght-imprv-12-0.59-0.77.hdf5\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7177 - accuracy: 0.5861 - f1_score: 0.7703\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7097 - accuracy: 0.5865 - f1_score: 0.7703\n",
      "Epoch 13: accuracy improved from 0.58608 to 0.58651, saving model to ./batch_size-62993\\wght-imprv-13-0.59-0.77.hdf5\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7097 - accuracy: 0.5865 - f1_score: 0.7703\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7006 - accuracy: 0.5909 - f1_score: 0.7703\n",
      "Epoch 14: accuracy improved from 0.58651 to 0.59089, saving model to ./batch_size-62993\\wght-imprv-14-0.59-0.77.hdf5\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7006 - accuracy: 0.5909 - f1_score: 0.7703\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6975 - accuracy: 0.5912 - f1_score: 0.7703\n",
      "Epoch 15: accuracy improved from 0.59089 to 0.59124, saving model to ./batch_size-62993\\wght-imprv-15-0.59-0.77.hdf5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6975 - accuracy: 0.5912 - f1_score: 0.7703\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.5915 - f1_score: 0.7703\n",
      "Epoch 16: accuracy improved from 0.59124 to 0.59148, saving model to ./batch_size-62993\\wght-imprv-16-0.59-0.77.hdf5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6920 - accuracy: 0.5915 - f1_score: 0.7703\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6877 - accuracy: 0.5926 - f1_score: 0.7703\n",
      "Epoch 17: accuracy improved from 0.59148 to 0.59259, saving model to ./batch_size-62993\\wght-imprv-17-0.59-0.77.hdf5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6877 - accuracy: 0.5926 - f1_score: 0.7703\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6768 - accuracy: 0.6007 - f1_score: 0.7703\n",
      "Epoch 18: accuracy improved from 0.59259 to 0.60067, saving model to ./batch_size-62993\\wght-imprv-18-0.60-0.77.hdf5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6768 - accuracy: 0.6007 - f1_score: 0.7703\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6738 - accuracy: 0.5993 - f1_score: 0.7703\n",
      "Epoch 19: accuracy did not improve from 0.60067\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6738 - accuracy: 0.5993 - f1_score: 0.7703\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6653 - accuracy: 0.6021 - f1_score: 0.7703\n",
      "Epoch 20: accuracy improved from 0.60067 to 0.60207, saving model to ./batch_size-62993\\wght-imprv-20-0.60-0.77.hdf5\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6653 - accuracy: 0.6021 - f1_score: 0.7703\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6562 - accuracy: 0.6029 - f1_score: 0.7703\n",
      "Epoch 21: accuracy improved from 0.60207 to 0.60294, saving model to ./batch_size-62993\\wght-imprv-21-0.60-0.77.hdf5\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6562 - accuracy: 0.6029 - f1_score: 0.7703\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6483 - accuracy: 0.6071 - f1_score: 0.7703\n",
      "Epoch 22: accuracy improved from 0.60294 to 0.60707, saving model to ./batch_size-62993\\wght-imprv-22-0.61-0.77.hdf5\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6483 - accuracy: 0.6071 - f1_score: 0.7703\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6383 - accuracy: 0.6121 - f1_score: 0.7703\n",
      "Epoch 23: accuracy improved from 0.60707 to 0.61210, saving model to ./batch_size-62993\\wght-imprv-23-0.61-0.77.hdf5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6383 - accuracy: 0.6121 - f1_score: 0.7703\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6292 - accuracy: 0.6126 - f1_score: 0.7703\n",
      "Epoch 24: accuracy improved from 0.61210 to 0.61262, saving model to ./batch_size-62993\\wght-imprv-24-0.61-0.77.hdf5\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6292 - accuracy: 0.6126 - f1_score: 0.7703\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6183 - accuracy: 0.6171 - f1_score: 0.7703\n",
      "Epoch 25: accuracy improved from 0.61262 to 0.61710, saving model to ./batch_size-62993\\wght-imprv-25-0.62-0.77.hdf5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6183 - accuracy: 0.6171 - f1_score: 0.7703\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6084 - accuracy: 0.6190 - f1_score: 0.7703\n",
      "Epoch 26: accuracy improved from 0.61710 to 0.61902, saving model to ./batch_size-62993\\wght-imprv-26-0.62-0.77.hdf5\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6084 - accuracy: 0.6190 - f1_score: 0.7703\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6013 - accuracy: 0.6170 - f1_score: 0.7703\n",
      "Epoch 27: accuracy did not improve from 0.61902\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6013 - accuracy: 0.6170 - f1_score: 0.7703\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5938 - accuracy: 0.6222 - f1_score: 0.7703\n",
      "Epoch 28: accuracy improved from 0.61902 to 0.62220, saving model to ./batch_size-62993\\wght-imprv-28-0.62-0.77.hdf5\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5938 - accuracy: 0.6222 - f1_score: 0.7703\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5823 - accuracy: 0.6246 - f1_score: 0.7703\n",
      "Epoch 29: accuracy improved from 0.62220 to 0.62459, saving model to ./batch_size-62993\\wght-imprv-29-0.62-0.77.hdf5\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5823 - accuracy: 0.6246 - f1_score: 0.7703\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5749 - accuracy: 0.6303 - f1_score: 0.7703\n",
      "Epoch 30: accuracy improved from 0.62459 to 0.63026, saving model to ./batch_size-62993\\wght-imprv-30-0.63-0.77.hdf5\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5749 - accuracy: 0.6303 - f1_score: 0.7703\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5623 - accuracy: 0.6322 - f1_score: 0.7703\n",
      "Epoch 31: accuracy improved from 0.63026 to 0.63217, saving model to ./batch_size-62993\\wght-imprv-31-0.63-0.77.hdf5\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5623 - accuracy: 0.6322 - f1_score: 0.7703\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.6371 - f1_score: 0.7703\n",
      "Epoch 32: accuracy improved from 0.63217 to 0.63710, saving model to ./batch_size-62993\\wght-imprv-32-0.64-0.77.hdf5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5525 - accuracy: 0.6371 - f1_score: 0.7703\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.6479 - f1_score: 0.7703\n",
      "Epoch 33: accuracy improved from 0.63710 to 0.64794, saving model to ./batch_size-62993\\wght-imprv-33-0.65-0.77.hdf5\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5396 - accuracy: 0.6479 - f1_score: 0.7703\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.6543 - f1_score: 0.7703\n",
      "Epoch 34: accuracy improved from 0.64794 to 0.65434, saving model to ./batch_size-62993\\wght-imprv-34-0.65-0.77.hdf5\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5281 - accuracy: 0.6543 - f1_score: 0.7703\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5206 - accuracy: 0.6580 - f1_score: 0.7703\n",
      "Epoch 35: accuracy improved from 0.65434 to 0.65799, saving model to ./batch_size-62993\\wght-imprv-35-0.66-0.77.hdf5\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5206 - accuracy: 0.6580 - f1_score: 0.7703\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5136 - accuracy: 0.6630 - f1_score: 0.7703\n",
      "Epoch 36: accuracy improved from 0.65799 to 0.66301, saving model to ./batch_size-62993\\wght-imprv-36-0.66-0.77.hdf5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5136 - accuracy: 0.6630 - f1_score: 0.7703\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4979 - accuracy: 0.6776 - f1_score: 0.7703\n",
      "Epoch 37: accuracy improved from 0.66301 to 0.67765, saving model to ./batch_size-62993\\wght-imprv-37-0.68-0.77.hdf5\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.4979 - accuracy: 0.6776 - f1_score: 0.7703\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4903 - accuracy: 0.6840 - f1_score: 0.7703\n",
      "Epoch 38: accuracy improved from 0.67765 to 0.68396, saving model to ./batch_size-62993\\wght-imprv-38-0.68-0.77.hdf5\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4903 - accuracy: 0.6840 - f1_score: 0.7703\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4775 - accuracy: 0.6959 - f1_score: 0.7703\n",
      "Epoch 39: accuracy improved from 0.68396 to 0.69589, saving model to ./batch_size-62993\\wght-imprv-39-0.70-0.77.hdf5\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4775 - accuracy: 0.6959 - f1_score: 0.7703\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.7071 - f1_score: 0.7703\n",
      "Epoch 40: accuracy improved from 0.69589 to 0.70714, saving model to ./batch_size-62993\\wght-imprv-40-0.71-0.77.hdf5\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4635 - accuracy: 0.7071 - f1_score: 0.7703\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4519 - accuracy: 0.7192 - f1_score: 0.7703\n",
      "Epoch 41: accuracy improved from 0.70714 to 0.71918, saving model to ./batch_size-62993\\wght-imprv-41-0.72-0.77.hdf5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4519 - accuracy: 0.7192 - f1_score: 0.7703\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.7301 - f1_score: 0.7703\n",
      "Epoch 42: accuracy improved from 0.71918 to 0.73008, saving model to ./batch_size-62993\\wght-imprv-42-0.73-0.77.hdf5\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4449 - accuracy: 0.7301 - f1_score: 0.7703\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4280 - accuracy: 0.7433 - f1_score: 0.7703\n",
      "Epoch 43: accuracy improved from 0.73008 to 0.74330, saving model to ./batch_size-62993\\wght-imprv-43-0.74-0.77.hdf5\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4280 - accuracy: 0.7433 - f1_score: 0.7703\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4093 - accuracy: 0.7580 - f1_score: 0.7703\n",
      "Epoch 44: accuracy improved from 0.74330 to 0.75797, saving model to ./batch_size-62993\\wght-imprv-44-0.76-0.77.hdf5\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4093 - accuracy: 0.7580 - f1_score: 0.7703\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.7700 - f1_score: 0.7703\n",
      "Epoch 45: accuracy improved from 0.75797 to 0.76996, saving model to ./batch_size-62993\\wght-imprv-45-0.77-0.77.hdf5\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4020 - accuracy: 0.7700 - f1_score: 0.7703\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3898 - accuracy: 0.7789 - f1_score: 0.7703\n",
      "Epoch 46: accuracy improved from 0.76996 to 0.77888, saving model to ./batch_size-62993\\wght-imprv-46-0.78-0.77.hdf5\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3898 - accuracy: 0.7789 - f1_score: 0.7703\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.7939 - f1_score: 0.7703\n",
      "Epoch 47: accuracy improved from 0.77888 to 0.79391, saving model to ./batch_size-62993\\wght-imprv-47-0.79-0.77.hdf5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3752 - accuracy: 0.7939 - f1_score: 0.7703\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.8049 - f1_score: 0.7703\n",
      "Epoch 48: accuracy improved from 0.79391 to 0.80487, saving model to ./batch_size-62993\\wght-imprv-48-0.80-0.77.hdf5\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3586 - accuracy: 0.8049 - f1_score: 0.7703\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3520 - accuracy: 0.8122 - f1_score: 0.7703\n",
      "Epoch 49: accuracy improved from 0.80487 to 0.81220, saving model to ./batch_size-62993\\wght-imprv-49-0.81-0.77.hdf5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3520 - accuracy: 0.8122 - f1_score: 0.7703\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.8193 - f1_score: 0.7703\n",
      "Epoch 50: accuracy improved from 0.81220 to 0.81933, saving model to ./batch_size-62993\\wght-imprv-50-0.82-0.77.hdf5\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3386 - accuracy: 0.8193 - f1_score: 0.7703\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [5,25,125,625,3125,15625,62993]:\n",
    "    #Define the model architecture\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(78, activation='relu', input_shape = (39,)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(156, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(25, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Create an instance of the F1Score metric.\n",
    "    f1_score = F1Score(num_classes=2, average='micro')\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy', f1_score])\n",
    "\n",
    "    filepath=\"./batch_size-\" + str(batch_size) + \"/wght-imprv-{epoch:02d}-{accuracy:.2f}-{f1_score:.2f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=50, batch_size=batch_size, callbacks=callbacks_list)\n",
    "    model.save_weights(\"./batch_size-\" + str(batch_size) + \"/50.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493/493 - 2s - loss: 0.0025 - accuracy: 0.9996 - f1_score: 0.9997 - 2s/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0024945661425590515, 0.9996190071105957, 0.9996922612190247]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"./batch_size-25/50.hdf5\")\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493/493 - 2s - loss: 0.0102 - accuracy: 0.9996 - f1_score: 0.9956 - 2s/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.010198471136391163, 0.9995555281639099, 0.995607316493988]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"./batch_size-5/50.hdf5\")\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
